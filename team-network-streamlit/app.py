import os, io, json, base64, re
import numpy as np
import pandas as pd
import streamlit as st
from streamlit.components.v1 import html
import networkx as nx
from pyvis.network import Network
import matplotlib.pyplot as plt
from openai import OpenAI
from matplotlib import font_manager  

# -----------------------------------------
# ğŸ” OpenAI Client (ì´ë¯¸ì§€ ìƒì„± ì œì™¸, í…ìŠ¤íŠ¸ ê¸°ëŠ¥ë§Œ)
# -----------------------------------------
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])


# ---------------- í•œê¸€ í°íŠ¸ ì„¤ì • (NanumGothic) ----------------
FONT_PATH = os.path.join(os.path.dirname(__file__), "lib", "NanumGothic.ttf")

if os.path.exists(FONT_PATH):
    font_manager.fontManager.addfont(FONT_PATH)
    plt.rcParams["font.family"] = "NanumGothic"
    plt.rcParams["axes.unicode_minus"] = False  # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
else:
    # ë¡œì»¬/í´ë¼ìš°ë“œì—ì„œ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ê²½ê³ ë§Œ ë„ìš°ê³  ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
    st.warning(f"í•œê¸€ í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FONT_PATH}")




# -----------------------------------------
# ğŸ“Œ Streamlit ê¸°ë³¸ ì„¤ì •
# -----------------------------------------
st.set_page_config(page_title="ë°ì´í„°ë¶„ì„ë© ì¸ì  ë„¤íŠ¸ì›Œí¬", layout="wide")
st.title("ğŸ•¸ï¸ ë°ì´í„°ë¶„ì„ë© ì¸ì  ë„¤íŠ¸ì›Œí¬ v2")

st.markdown(
    """
íŒ€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ + MBTI í†µê³„ + í¬ìŠ¤í„° ë·° + AI ë¶„ì„ ë„êµ¬ê°€ í¬í•¨ëœ ì‹œê°í™” ë„êµ¬ì…ë‹ˆë‹¤.
"""
)

# ==========================================
# ğŸ§© Sidebar
# ==========================================
st.sidebar.header("âš™ï¸ ì‹œê°í™” ì„¤ì •")
physics = st.sidebar.selectbox("ë¬¼ë¦¬ì—”ì§„", ["barnes_hut", "force_atlas_2based", "repulsion"], index=1)
base_node_size = st.sidebar.slider("ê¸°ë³¸ ë…¸ë“œ í¬ê¸°", 5, 60, 16)
degree_scale = st.sidebar.slider("ì°¨ìˆ˜ ê¸°ë°˜ í¬ê¸° ìŠ¤ì¼€ì¼", 0, 40, 5)
show_labels = st.sidebar.checkbox("ì´ë¦„ ë¼ë²¨ í‘œì‹œ", value=True)

# -----------------------------------------
# ğŸ” MBTI í•„í„°
# -----------------------------------------
st.sidebar.markdown("---")
st.sidebar.header("ğŸ” MBTI í•„í„°")
ei_filter = st.sidebar.selectbox("E/I í•„í„°", ["(ì „ì²´)", "Eë§Œ", "Ië§Œ"], index=0)
tf_filter = st.sidebar.selectbox("T/F í•„í„°", ["(ì „ì²´)", "Të§Œ", "Fë§Œ"], index=0)
mbti_exact_placeholder = st.sidebar.empty()

# -----------------------------------------
# ğŸ§µ ì—£ì§€ íƒ€ì… í† ê¸€
# -----------------------------------------
st.sidebar.markdown("---")
st.sidebar.header("ğŸ§µ ì—£ì§€ íƒ€ì… í† ê¸€")

show_edge_all      = st.sidebar.checkbox("ì „ì²´", value=False)

show_edge_dept     = st.sidebar.checkbox("ì†Œì†", value=True)
show_edge_role     = st.sidebar.checkbox("ì§ìœ„", value=False)
show_edge_birth    = st.sidebar.checkbox("íƒ„ìƒë…„ë„", value=True)
show_edge_cohort   = st.sidebar.checkbox("ë™ê¸°", value=False)
show_edge_kakao    = st.sidebar.checkbox("ì¹´ì¹´ì˜¤ ë¶„ì‚¬", value=False)
show_edge_sex      = st.sidebar.checkbox("ì„±ë³„", value=False)
show_edge_joinyear = st.sidebar.checkbox("ì…ì‚¬ë…„ë„", value=False)
show_edge_mbti     = st.sidebar.checkbox("MBTI", value=True)
show_edge_blood    = st.sidebar.checkbox("í˜ˆì•¡í˜•", value=True)

# -----------------------------------------
# ê²€ìƒ‰ ë°•ìŠ¤
# -----------------------------------------
st.sidebar.markdown("---")
search_box_placeholder = st.sidebar.empty()

# -----------------------------------------
# ë°ì´í„° ì—…ë¡œë“œ
# -----------------------------------------
st.sidebar.markdown("---")
st.sidebar.header("ğŸ“„ ë°ì´í„° ì—…ë¡œë“œ")
uploaded_csv = st.sidebar.file_uploader("íŒ€ CSV ì—…ë¡œë“œ", type=["csv"])
uploaded_imgs = st.sidebar.file_uploader(
    "ë…¸ë“œ ì‚¬ì§„ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)", 
    type=["png", "jpg", "jpeg"], 
    accept_multiple_files=True
)

# ==========================================
# ğŸ§± Default CSV
# ==========================================
default_csv = """ì´ë¦„,ldap,ì†Œì†,ì§ìœ„,ì§êµ°,íƒ„ìƒë…„ë„,ì…ì‚¬ë…„ë„,MBTI,í˜ˆì•¡í˜•,ë™ê¸° ì—¬ë¶€,ì¹´ì¹´ì˜¤ë¶„ì‚¬,ì„±ë³„,ì›Œí¬ìƒµ ì„±í–¥(2022),ì›Œí¬ìƒµì„±í–¥(2025),ê±°ì£¼ì§€,ê²°í˜¼ì—¬ë¶€,Image
ê¹€ìˆ˜í˜•,cantabile.58,ë°ì´í„°ë¶„ì„ë©,ì‹¤ì¥,ê°œë°œ,1970,2015,INTP,O,,ì¹´ì¹´ì˜¤,ë‚¨ì,íë§,íë§,ê²½ê¸°ë„,ê¸°í˜¼,cantabile.png
ê¹€ì„ ì˜,party.92,BIì…€,ì…€ì¥,ê¸°ìˆ ,1984,2016,ESFJ,A,,ì¹´ì¹´ì˜¤,ì—¬ì,íë§,íë§,ê²½ê¸°ë„,ê¸°í˜¼,party.png
ì†¡ëŒ€ì„­,steven.song,BIì…€,ì…€ì›,ê°œë°œ,1989,2018.1.22,ISTP,O,,,ë‚¨ì,íë§,íë§,ê²½ê¸°ë„,ë¯¸í˜¼,steven.png
ì´ë‚˜ì—°,zoe.lee93,BIì…€,ì…€ì›,ê°œë°œ,1993,2022.1.17,INFJ,A,,,ì—¬ì,ì•¡í‹°ë¹„í‹°,íë§,ì„œìš¸,ë¯¸í˜¼,zoe.png
ìœ ì„ ì •,saylor.u,BIì…€,ì…€ì›,ê¸°ìˆ ,1994,2023.5.2,INFP,A,,,ì—¬ì,,ì•¡í‹°ë¹„í‹°,ê²½ê¸°ë„,ë¯¸í˜¼,saylor.png
ì¡°ìŠ¹ë¯¼,noah.94,BIì…€,ì…€ì›,ê¸°ìˆ ,1994,2024.10.28,ESFJ,A,2024 ê²½ë ¥ì§ ë™ê¸°,,ë‚¨ì,,ì•¡í‹°ë¹„í‹°,ê²½ê¸°ë„,ê¸°í˜¼,noah.png
ê¹€ìš©í™˜,feno.meno,BIì…€,ì…€ì›,ê°œë°œ,1994,2024.11.18,INFP,AB,2024 ê²½ë ¥ì§ ë™ê¸°,,ë‚¨ì,,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ë¯¸í˜¼,feno.png
ê°•ë™ì§„,sonny.kang,BIì…€,ì…€ì›,ê¸°ìˆ ,1995,2021.6.23,ESFP,A,2021 ì¸í„´ ë™ê¸°,,ë‚¨ì,ì•¡í‹°ë¹„í‹°,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ë¯¸í˜¼,sonny.png
ì¡°ìœ¤ì˜,zoey.cho,BIì…€,ì…€ì›,ê°œë°œ,1996,2021.6.23,INTJ,B,2021 ì¸í„´ ë™ê¸°,,ì—¬ì,ì•¡í‹°ë¹„í‹°,íë§,ì„œìš¸,ê¸°í˜¼,zoey.png
ì¡°ì€í¬,alysia.c,ë°ì´í„°í…Œí¬ì…€,ì…€ì¥,ê°œë°œ,1980,2017,ISTP,A,,ì¹´ì¹´ì˜¤,ì—¬ì,íë§,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,alysia.png
ì •ë™ì£¼,dj.jeong,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1988,2017.3.20,ISFP,AB,,,ì—¬ì,íë§,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,dj.png
ìœ¤íƒœì‹,levi.y,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1992,2020.12.22,ENTJ,B,,,ë‚¨ì,ì•¡í‹°ë¹„í‹°,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,levi.png
ì´ì°½ìš±,carl.lee,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1993,2021.11.30,INTP,B,2021 ê³µì±„ ë™ê¸°,,ë‚¨ì,íë§,ì•¡í‹°ë¹„í‹°,ê²½ê¸°ë„,ë¯¸í˜¼,carl.png
ê¹€ë²”ì¤€,breadly.abc,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1994,2024.11.18,ISFJ,O,2024 ê²½ë ¥ì§ ë™ê¸°,,ë‚¨ì,,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,breadly.png
ê¹€í¬ì›,wonnie.kim,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1997,2021.6.23,ENFP,B,2021 ì¸í„´ ë™ê¸°,,ì—¬ì,ì•¡í‹°ë¹„í‹°,íë§,ì„œìš¸,ë¯¸í˜¼,wonnie.png
ë°•ì¢…ë²”,jaybe.park,ì´ìƒíƒì§€ì…€,ì…€ì¥,ê°œë°œ,1990,2019,ESTP,A,,,ë‚¨ì,ì•¡í‹°ë¹„í‹°,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,jaybe.png
ì£¼ì² ë¯¼,iron.min,ì´ìƒíƒì§€ì…€,ì…€ì›,ê°œë°œ,1988,2018.9.18,INFJ,B,,,ë‚¨ì,íë§,íë§,ê²½ê¸°ë„,ë¯¸í˜¼,iron.png
ê¹€ìš°ì˜,walt.kim,ì´ìƒíƒì§€ì…€,ì…€ì›,ê°œë°œ,1990,2020.11.24,,O,,,ë‚¨ì,ì•¡í‹°ë¹„í‹°,íë§,ê²½ê¸°ë„,ë¯¸í˜¼,walt.png
ì´ì¢…ìš°,justin.dev,ì´ìƒíƒì§€ì…€,ì…€ì›,ê°œë°œ,1995,2021.11.17,INTJ,B,2021 ê³µì±„ ë™ê¸°,,ë‚¨ì,íë§,íë§,ê²½ê¸°ë„,ë¯¸í˜¼,justin.png
ê¹€í˜œì •,molly.ouo,ì´ìƒíƒì§€ì…€,ì…€ì›,ê°œë°œ,1999,2023.1.16,ENFJ,B,,,ì—¬ì,,íë§,ì„œìš¸,ë¯¸í˜¼,molly.png
"""

# -----------------------------------------
# CSV ë¡œë“œ
# -----------------------------------------
if uploaded_csv:
    df = pd.read_csv(uploaded_csv)
else:
    df = pd.read_csv(io.StringIO(default_csv))

df.columns = [c.strip() for c in df.columns]
if "Image" in df.columns and "image" not in df.columns:
    df["image"] = df["Image"]

df = df.map(lambda x: x.strip() if isinstance(x, str) else x)


# -----------------------------------------
# ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬
# -----------------------------------------
IMG_DIR = "node_images"
os.makedirs(IMG_DIR, exist_ok=True)

if uploaded_imgs:
    for f in uploaded_imgs:
        with open(os.path.join(IMG_DIR, f.name), "wb") as out:
            out.write(f.read())

# -----------------------------------------
# ì´ë¯¸ì§€ íŒŒì¼ ë§¤ì¹­ í•¨ìˆ˜
# -----------------------------------------
def _variants(name: str):
    if not name:
        return []
    base, ext = os.path.splitext(str(name).strip())
    yield f"{base}{ext}"
    yield f"{base.lower()}{ext.lower()}"
    for e in (".png", ".jpg", ".jpeg", ".PNG", ".JPG", ".JPEG"):
        yield f"{base}{e}"
        yield f"{base.lower()}{e}"

MISSING_IMAGES = set()

def file_to_data_url(path: str) -> str:
    ext = os.path.splitext(path)[1].lower()
    mime = "image/png" if ext == ".png" else "image/jpeg"
    with open(path, "rb") as f:
        data = base64.b64encode(f.read()).decode("ascii")
    return f"data:{mime};base64,{data}"

def resolve_image(row):
    img_col = str(row.get("image", "") or "").strip()
    ldap_val = str(row.get("ldap", "") or "").strip()

    # URL ë˜ëŠ” base64ë©´ ë°”ë¡œ ì‚¬ìš©
    if img_col.startswith(("http://", "https://", "data:")):
        return img_col

    candidates = []
    for v in _variants(img_col):
        candidates.append(os.path.join(IMG_DIR, v))

    if ldap_val:
        for ext in (".png", ".jpg", ".jpeg"):
            candidates.append(os.path.join(IMG_DIR, ldap_val + ext))
            candidates.append(os.path.join(IMG_DIR, ldap_val.lower() + ext))

    for path in candidates:
        if os.path.exists(path):
            return file_to_data_url(path)

    MISSING_IMAGES.add(f"{row.get('ì´ë¦„','?')} â†’ {img_col}")
    return "https://via.placeholder.com/120?text=No+Image"


# ==========================================
# ğŸ“Œ ì—°ë„ ì •ê·œí™” (94 â†’ 1994 ì²˜ë¦¬)
# ==========================================
YEAR_RE = re.compile(r"(19|20)\d{2}")

def extract_year(v):
    if v is None:
        return None
    s = str(v)

    # 4ìë¦¬ ì—°ë„ ë¨¼ì €
    m = YEAR_RE.search(s)
    if m:
        try:
            return int(m.group())
        except:
            pass

    # 2ìë¦¬ ì—°ë„ (50 ì´ìƒ = 1900ëŒ€, ë¯¸ë§Œ = 2000ëŒ€)
    m2 = re.search(r"(?<!\d)(\d{2})(?!\d)", s)
    if m2:
        yy = int(m2.group(1))
        return 1900 + yy if yy >= 50 else 2000 + yy
    return None

# ì„¸ëŒ€ êµ¬ë¶„ìš© í—¬í¼
def generation_from_year(y):
    if y is None or (isinstance(y, float) and np.isnan(y)):
        return None
    y = int(y)
    if y <= 1980:
        return "Xì„¸ëŒ€"
    elif y <= 1996:
        return "ë°€ë ˆë‹ˆì–¼"
    else:
        return "Zì„¸ëŒ€+"


df["íƒ„ìƒë…„ë„_Y"] = df["íƒ„ìƒë…„ë„"].apply(extract_year)
df["ì…ì‚¬ë…„ë„_Y"] = df["ì…ì‚¬ë…„ë„"].apply(extract_year)

# ==========================================
# ğŸ“Œ MBTI í•„í„° ì˜µì…˜ ë§Œë“¤ê¸°
# ==========================================
def mbti_list(series):
    vals = sorted([m for m in series.dropna().astype(str).unique() if m and m != "nan"])
    return ["(ì „ì²´)"] + vals

mbti_exact = mbti_exact_placeholder.selectbox(
    "ì •í™•íˆ ì„ íƒ",
    mbti_list(df["MBTI"]),
    index=0,
    key="mbti_exact_sel",
)

# -----------------------------------------
# MBTI í•„í„°ë§ í•¨ìˆ˜
# -----------------------------------------
def keep_by_ei(m):
    if ei_filter == "(ì „ì²´)" or not m:
        return True
    return (ei_filter == "Eë§Œ" and str(m)[0] == "E") or (ei_filter == "Ië§Œ" and str(m)[0] == "I")

def keep_by_tf(m):
    if tf_filter == "(ì „ì²´)" or not m:
        return True
    return (tf_filter == "Të§Œ" and str(m)[2:3] == "T") or (tf_filter == "Fë§Œ" and str(m)[2:3] == "F")

def keep_by_exact(m):
    return mbti_exact == "(ì „ì²´)" or str(m) == mbti_exact

mask = df.apply(lambda r: keep_by_exact(r["MBTI"]) and keep_by_ei(r["MBTI"]) and keep_by_tf(r["MBTI"]), axis=1)

df_vis = df[mask].copy()
if df_vis.empty:
    st.warning("âš ï¸ í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•˜ì„¸ìš”.")
    df_vis = df.copy()

# ==========================================
# ğŸ“Œ node_id ìƒì„± (ldap ì—†ìœ¼ë©´ ì´ë¦„)
# ==========================================
def node_id_from_row(r):
    ldap_val = str(r.get("ldap", "")).strip()
    return ldap_val if ldap_val else str(r["ì´ë¦„"])

df["node_id"] = df.apply(node_id_from_row, axis=1)
df_vis["node_id"] = df_vis.apply(node_id_from_row, axis=1)

# ==========================================
# ğŸ” ê²€ìƒ‰ ë°•ìŠ¤
# ==========================================
focus_node = ""
with search_box_placeholder.container():
    st.subheader("ğŸ” ë…¸ë“œ ê²€ìƒ‰")
    query = st.text_input("ì´ë¦„ ë˜ëŠ” LDAP ê²€ìƒ‰", key="search_query_input")

    if query:
        cond = (
            df_vis["ì´ë¦„"].astype(str).str.contains(query, case=False, na=False)
            | df_vis["ldap"].astype(str).str.contains(query, case=False, na=False)
        )
        matches = df_vis[cond]

        if not matches.empty:
            opts = [f"{row['ì´ë¦„']} ({row['ldap']})" for _, row in matches.iterrows()]
            sel = st.selectbox("ê²€ìƒ‰ ê²°ê³¼", opts, key="search_result_box")

            # LDAP ì„ íƒ
            if "(" in sel:
                chosen_ldap = sel.split("(")[-1][:-1]
                row = df[df["ldap"] == chosen_ldap].iloc[0]
                focus_node = row["node_id"]
        else:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==========================================
# ğŸ§© ìœ í‹¸ í•¨ìˆ˜: ê°’ ì¡´ì¬ ì—¬ë¶€
# ==========================================
def is_filled(v):
    if v is None:
        return False
    s = str(v).strip()
    return s not in ("", "nan", "None", "null")

def valid_equal(a, b):
    if not is_filled(a) or not is_filled(b):
        return False
    return str(a).strip() == str(b).strip()

# ==========================================
# ğŸ¨ MBTI ìƒ‰ìƒ ê·œì¹™
# ==========================================
MBTI_COLORS = {
    "INFJ": "#6366f1",
    "INFP": "#22c55e",
    "INTJ": "#0ea5e9",
    "INTP": "#6366f1",
    "ISFP": "#22c55e",
    "ENFP": "#f97316",
    "ENFJ": "#ec4899",
    "ESFJ": "#eab308",
    "ESFP": "#a855f7",
}

def mbti_color(m):
    return MBTI_COLORS.get(str(m).strip(), "#9ca3af")

# ==========================================
# ğŸŸ§ ì¹´ì¹´ì˜¤ ë¶„ì‚¬ ì—¬ë¶€ íŒë‹¨ (ì…ì‚¬ì „ íšŒì‚¬ í¬í•¨)
# ==========================================
def is_kakao_division(v):
    """ì…ì‚¬ì „ íšŒì‚¬ ì»¬ëŸ¼ì— 'ì¹´ì¹´ì˜¤' í¬í•¨í•˜ë©´ ì¹´ì¹´ì˜¤ ë¶„ì‚¬ ê·¸ë£¹"""
    if v is None:
        return False
    return "ì¹´ì¹´ì˜¤" in str(v)


# ==========================================
# ğŸ”— ë¹„ìŠ·í•œ ì‚¬ëŒ TOP3 ê³„ì‚° (ì—£ì§€ ìƒì„± ì¡°ê±´ê³¼ 100% ë™ì¼í•˜ê²Œ)
# ==========================================

similar_map = {}
rows_full = df.to_dict("records")

# ì´ˆê¸°í™”
for r in rows_full:
    similar_map[r["node_id"]] = []

# ------------------------------------------
# ëª¨ë“  ì‚¬ëŒ ìŒ ë¹„êµ
# ------------------------------------------
for i in range(len(rows_full)):
    for j in range(i + 1, len(rows_full)):
        r1, r2 = rows_full[i], rows_full[j]
        nid1, nid2 = r1["node_id"], r2["node_id"]

        reasons = []

        # ì†Œì†
        if (show_edge_all or show_edge_dept) and valid_equal(r1["ì†Œì†"], r2["ì†Œì†"]):
            reasons.append("ì†Œì†")

        # ì§ìœ„
        if (show_edge_all or show_edge_role) and valid_equal(r1["ì§ìœ„"], r2["ì§ìœ„"]):
            reasons.append("ì§ìœ„")

        # íƒ„ìƒë…„ë„
        if (show_edge_all or show_edge_birth) and valid_equal(
            extract_year(r1["íƒ„ìƒë…„ë„"]),
            extract_year(r2["íƒ„ìƒë…„ë„"]),
        ):
            reasons.append("íƒ„ìƒë…„ë„")

        # ë™ê¸°
        if (show_edge_all or show_edge_cohort) and valid_equal(
            r1["ë™ê¸° ì—¬ë¶€"], r2["ë™ê¸° ì—¬ë¶€"]
        ):
            reasons.append("ë™ê¸°")

        # ì¹´ì¹´ì˜¤ ë¶„ì‚¬ ì—¬ë¶€
        if (show_edge_all or show_edge_kakao):
            if is_kakao_division(r1["ì¹´ì¹´ì˜¤ë¶„ì‚¬"]) and is_kakao_division(r2["ì¹´ì¹´ì˜¤ë¶„ì‚¬"]):
                reasons.append("ì¹´ì¹´ì˜¤ ë¶„ì‚¬")

        # ì„±ë³„
        if (show_edge_all or show_edge_sex) and valid_equal(r1["ì„±ë³„"], r2["ì„±ë³„"]):
            reasons.append("ì„±ë³„")

        # ì…ì‚¬ë…„ë„
        if (show_edge_all or show_edge_joinyear) and valid_equal(
            extract_year(r1["ì…ì‚¬ë…„ë„"]),
            extract_year(r2["ì…ì‚¬ë…„ë„"]),
        ):
            reasons.append("ì…ì‚¬ë…„ë„")

        # MBTI
        if (show_edge_all or show_edge_mbti) and valid_equal(r1["MBTI"], r2["MBTI"]):
            reasons.append("MBTI")

        # í˜ˆì•¡í˜•
        if (show_edge_all or show_edge_blood) and valid_equal(r1["í˜ˆì•¡í˜•"], r2["í˜ˆì•¡í˜•"]):
            reasons.append("í˜ˆì•¡í˜•")

        score = len(reasons)
        if score == 0:
            continue

        reason_text = ", ".join(reasons)

        similar_map[nid1].append({
            "name": r2["ì´ë¦„"],
            "ldap": r2["ldap"],
            "score": score,
            "reasons": reason_text,
        })
        similar_map[nid2].append({
            "name": r1["ì´ë¦„"],
            "ldap": r1["ldap"],
            "score": score,
            "reasons": reason_text,
        })

# TOP3ë§Œ ë‚¨ê¸°ê¸°
for nid in similar_map:
    similar_map[nid].sort(key=lambda x: x["score"], reverse=True)
    similar_map[nid] = similar_map[nid][:3]


# ==========================================
# ğŸ•¸ Graph ìƒì„± í•¨ìˆ˜ (NetworkX ê¸°ë°˜)
# ==========================================

def make_graph(df_people: pd.DataFrame):
    G = nx.Graph()

    # -------------------------------------
    # ë…¸ë“œ ìƒì„±
    # -------------------------------------
    for _, r in df_people.iterrows():
        nid = r["node_id"]
        name = r["ì´ë¦„"]
        dept = r["ì†Œì†"]
        img = resolve_image(r)

        title = "<br>".join([
            f"ì´ë¦„: {name}",
            f"ldap: {r['ldap']}",
            f"ì†Œì†: {dept}",
            f"ì§ìœ„: {r['ì§ìœ„']}",
            f"ì§êµ°: {r['ì§êµ°']}",
            f"íƒ„ìƒë…„ë„: {extract_year(r['íƒ„ìƒë…„ë„'])}",
            f"ì…ì‚¬ë…„ë„: {extract_year(r['ì…ì‚¬ë…„ë„'])}",
            f"MBTI: {r['MBTI']}",
            f"í˜ˆì•¡í˜•: {r['í˜ˆì•¡í˜•']}",
            f"ë™ê¸° ì—¬ë¶€: {r['ë™ê¸° ì—¬ë¶€']}",
        ])

        border_color = mbti_color(r["MBTI"])

        node_kwargs = dict(
            title=title,
            group=dept,
            color={
                "border": border_color,
                "background": "#ffffff",
                "highlight": {"border": border_color, "background": "#ffffff"},
                "hover": {"border": border_color, "background": "#f9fafb"},
            },
        )

        if show_labels:
            node_kwargs["label"] = name
        if img:
            node_kwargs.update(shape="circularImage", image=img)

        G.add_node(nid, **node_kwargs)

    # -------------------------------------
    # ì—£ì§€ ìƒì„±
    # -------------------------------------
    rows = df_people.to_dict("records")

    for i in range(len(rows)):
        for j in range(i + 1, len(rows)):
            r1, r2 = rows[i], rows[j]
            reasons = []

            # ì—£ì§€ ì¡°ê±´ - ìœ ì‚¬ë„ ê³„ì‚°ê³¼ ë™ì¼í•˜ê²Œ
            if (show_edge_all or show_edge_dept) and valid_equal(r1["ì†Œì†"], r2["ì†Œì†"]):
                reasons.append(("ì†Œì†", "ê°™ì€ ì†Œì†"))

            if (show_edge_all or show_edge_role) and valid_equal(r1["ì§ìœ„"], r2["ì§ìœ„"]):
                reasons.append(("ì§ìœ„", "ê°™ì€ ì§ìœ„"))

            if (show_edge_all or show_edge_birth) and valid_equal(
                extract_year(r1["íƒ„ìƒë…„ë„"]),
                extract_year(r2["íƒ„ìƒë…„ë„"]),
            ):
                reasons.append(("íƒ„ìƒë…„ë„", "ê°™ì€ íƒ„ìƒë…„ë„"))

            if (show_edge_all or show_edge_cohort) and valid_equal(
                r1["ë™ê¸° ì—¬ë¶€"], r2["ë™ê¸° ì—¬ë¶€"]
            ):
                reasons.append(("ë™ê¸°", "ê°™ì€ ë™ê¸°"))

            if (show_edge_all or show_edge_kakao):
                if is_kakao_division(r1["ì¹´ì¹´ì˜¤ë¶„ì‚¬"]) and is_kakao_division(r2["ì¹´ì¹´ì˜¤ë¶„ì‚¬"]):
                    reasons.append(("ì¹´ì¹´ì˜¤", "ì¹´ì¹´ì˜¤ ë¶„ì‚¬"))

            if (show_edge_all or show_edge_sex) and valid_equal(r1["ì„±ë³„"], r2["ì„±ë³„"]):
                reasons.append(("ì„±ë³„", "ê°™ì€ ì„±ë³„"))

            if (show_edge_all or show_edge_joinyear) and valid_equal(
                extract_year(r1["ì…ì‚¬ë…„ë„"]),
                extract_year(r2["ì…ì‚¬ë…„ë„"]),
            ):
                reasons.append(("ì…ì‚¬ë…„ë„", "ê°™ì€ ì…ì‚¬ë…„ë„"))

            if (show_edge_all or show_edge_mbti) and valid_equal(
                r1["MBTI"], r2["MBTI"]
            ):
                reasons.append(("MBTI", "ê°™ì€ MBTI"))

            if (show_edge_all or show_edge_blood) and valid_equal(
                r1["í˜ˆì•¡í˜•"], r2["í˜ˆì•¡í˜•"]
            ):
                reasons.append(("í˜ˆì•¡í˜•", "ê°™ì€ í˜ˆì•¡í˜•"))

            if len(reasons) == 0:
                continue

            weight = len(reasons)
            main_edge_type = reasons[0][0]
            labels = [lab for _, lab in reasons]

            title = " / ".join(labels) + f" (ì¡°ê±´ {weight}ê°œ ì¼ì¹˜)"

            G.add_edge(
                r1["node_id"], 
                r2["node_id"],
                weight=weight,
                title=title,
                edge_type=main_edge_type
            )

    return G


# ==========================================
# ğŸ•¸ ì‹¤ì œ ê·¸ë˜í”„ ìƒì„±
# ==========================================
G = make_graph(df_vis)
deg = dict(G.degree())

# ==========================================
# ğŸ“Š ë„¤íŠ¸ì›Œí¬ í†µê³„ (ë™ì¼ ì†Œì† / MBTI / ë™ê¸° ìˆ˜)
# ==========================================
dept_map = df.set_index("node_id")["ì†Œì†"].to_dict()
mbti_map = df.set_index("node_id")["MBTI"].to_dict()
cohort_map = df.set_index("node_id")["ë™ê¸° ì—¬ë¶€"].to_dict()

stats = {}
for nid in G.nodes():
    dept = dept_map.get(nid)
    mbti = mbti_map.get(nid)
    cohort = cohort_map.get(nid)

    stats[nid] = {
        "degree": deg.get(nid, 0),
        "same_dept": sum(1 for v in dept_map.values() if v == dept) - 1 if dept else 0,
        "same_mbti": sum(1 for v in mbti_map.values() if v == mbti) - 1 if mbti else 0,
        "same_cohort": sum(1 for v in cohort_map.values() if v == cohort) - 1 if cohort else 0,
    }

# ë…¸ë“œ í¬ê¸° ê²°ì •
def sized(nid):
    row = df[df["node_id"] == nid].iloc[0]
    rank = row["ì§ìœ„"]
    base_rank = {"ì‹¤ì¥": 20, "ì…€ì¥": 16, "ì…€ì›": 12}.get(rank, 12)
    return base_node_size + base_rank + degree_scale * deg.get(nid, 0)



# ==========================================
# ğŸ–¥ PyVis ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
# ==========================================

net = Network(height="820px", width="100%", bgcolor="#ffffff", font_color="black")

# ë¬¼ë¦¬ ì—”ì§„ ì„ íƒ
if physics == "barnes_hut":
    net.barnes_hut()
elif physics == "force_atlas_2based":
    net.force_atlas_2based()
else:
    net.repulsion()

# ==========================================
# ğŸ“Œ ë ˆì´ì•„ì›ƒ ì„¤ì • (ì†Œì† = Xì¶• / ë™ê¸° = Yì¶•)
# ==========================================

depths = sorted(df_vis["ì†Œì†"].dropna().unique())
depth_x = {d: i * 400 for i, d in enumerate(depths)}

cohorts = df_vis["ë™ê¸° ì—¬ë¶€"].dropna().astype(str).str.strip()
cohort_vals = sorted([c for c in cohorts.unique() if c])
cohort_y = {c: idx * 250 for idx, c in enumerate(cohort_vals)}
cohort_y["(none)"] = len(cohort_vals) * 250

# ==========================================
# ğŸ§© ë…¸ë“œ PyVisì— ì‚½ì…
# ==========================================

for nid, data in G.nodes(data=True):
    row = df[df["node_id"] == nid].iloc[0]

    dept = str(row["ì†Œì†"])
    cohort = str(row["ë™ê¸° ì—¬ë¶€"]).strip()

    x = depth_x.get(dept, 0)
    y = cohort_y.get(cohort if cohort else "(none)", 0)

    net.add_node(
        nid,
        size=sized(nid),
        x=x,
        y=y,
        physics=True,
        **data
    )

# ==========================================
# ğŸ¨ ì—£ì§€ ìƒ‰ìƒ ê·œì¹™
# ==========================================

EDGE_COLORS = {
    "ì†Œì†": "#22c55e",
    "ì§ìœ„": "#16a34a",
    "íƒ„ìƒë…„ë„": "#0ea5e9",
    "ë™ê¸°": "#3b82f6",
    "ì¹´ì¹´ì˜¤": "#f59e0b",
    "ì„±ë³„": "#ec4899",
    "ì…ì‚¬ë…„ë„": "#a855f7",
    "MBTI": "#ef4444",
    "í˜ˆì•¡í˜•": "#f97316",
    "ê¸°íƒ€": "#9ca3af",
}

# ==========================================
# ğŸ§µ ì—£ì§€ ì‚½ì… (ë‘ê»˜ = weight, ìƒ‰ìƒ = edge_type)
# ==========================================

for u, v, e in G.edges(data=True):
    edge_type = e.get("edge_type", "ê¸°íƒ€")
    color = EDGE_COLORS.get(edge_type, "#9ca3af")

    w = e.get("weight", 1)
    thickness = 1 + (w * 1.3)
    length = max(80, 280 - 40 * w)

    net.add_edge(
        u, v,
        value=thickness,
        color=color,
        title=e.get("title", ""),
        length=length,
    )

# ==========================================
# ğŸ—‚ HTML ìƒì„±
# ==========================================

html_file = "network.html"
net.save_graph(html_file)
with open(html_file, "r", encoding="utf-8") as f:
    html_src = f.read()

# ==========================================
# ğŸ› í´ë¦­ ì‹œ ìƒì„¸ ì •ë³´ íŒ¨ë„ + í¬ì»¤ì‹± ê¸°ëŠ¥ (JS)
# ==========================================

meta = {}
for _, r in df.iterrows():
    nid = r["node_id"]
    meta[nid] = {
        "ì´ë¦„": r["ì´ë¦„"],
        "ldap": r["ldap"],
        "ì†Œì†": r["ì†Œì†"],
        "ì§ìœ„": r["ì§ìœ„"],
        "ì§êµ°": r["ì§êµ°"],
        "ì…ì‚¬ë…„ë„": extract_year(r["ì…ì‚¬ë…„ë„"]),
        "MBTI": r["MBTI"],
        "í˜ˆì•¡í˜•": r["í˜ˆì•¡í˜•"],
        "ë™ê¸° ì—¬ë¶€": r["ë™ê¸° ì—¬ë¶€"],
        "ì—°ê²° ìˆ˜": stats[nid]["degree"],
        "ê°™ì€ ì†Œì† ìˆ˜": stats[nid]["same_dept"],
        "ê°™ì€ MBTI ìˆ˜": stats[nid]["same_mbti"],
        "ê°™ì€ ë™ê¸° ìˆ˜": stats[nid]["same_cohort"],
        "similar": similar_map.get(nid, []),
    }

focus_node_json = json.dumps(focus_node, ensure_ascii=False)

panel_js = f"""
<script>
window.nodeMeta = {json.dumps(meta, ensure_ascii=False)};

(function waitForNetwork() {{
  // ğŸ”„ network ê°ì²´ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ê³„ì† ì¬ì‹œë„
  if (typeof network === 'undefined' || !network.body) {{
    setTimeout(waitForNetwork, 300);
    return;
  }}

  const panelId = 'profilePanel';
  let panel = document.getElementById(panelId);

  if (!panel) {{
    panel = document.createElement('div');
    panel.id = panelId;
    panel.style.position='fixed';
    panel.style.top='20px';
    panel.style.right='20px';
    panel.style.width='260px';
    panel.style.maxHeight='70vh';
    panel.style.overflow='auto';
    panel.style.border='1px solid #e5e7eb';
    panel.style.borderRadius='12px';
    panel.style.padding='10px';
    panel.style.background='rgba(255,255,255,0.93)';
    panel.style.boxShadow='0 4px 12px rgba(0,0,0,0.15)';
    panel.style.fontSize='13px';
    panel.style.lineHeight='1.35';
    panel.innerHTML = '<b>ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</b><br><small>ë¹ˆ ê³µê°„ì„ í´ë¦­í•˜ë©´ ì „ì²´ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ì‹œ ë³´ì…ë‹ˆë‹¤.</small>';
    document.body.appendChild(panel);
  }}

  function showOnlyConnected(nid) {{
    const connectedNodes = network.getConnectedNodes(nid);
    connectedNodes.push(nid);

    const allNodeIds = network.body.data.nodes.getIds();
    const allEdgeIds = network.body.data.edges.getIds();

    // ë…¸ë“œ ìˆ¨ê¹€/í‘œì‹œ
    allNodeIds.forEach(function(id) {{
      const visible = connectedNodes.indexOf(id) !== -1;
      network.body.data.nodes.update({{ id: id, hidden: !visible }});
    }});

    // ì—£ì§€ ìˆ¨ê¹€/í‘œì‹œ
    const connectedEdges = network.getConnectedEdges(nid);
    allEdgeIds.forEach(function(id) {{
      const visible = connectedEdges.indexOf(id) !== -1;
      network.body.data.edges.update({{ id: id, hidden: !visible }});
    }});

    try {{
      network.focus(nid, {{ scale: 1.5, animation: true }});
    }} catch (e) {{}}
  }}

  function resetAll() {{
    const allNodeIds = network.body.data.nodes.getIds();
    const allEdgeIds = network.body.data.edges.getIds();

    allNodeIds.forEach(function(id) {{
      network.body.data.nodes.update({{ id: id, hidden: false }});
    }});
    allEdgeIds.forEach(function(id) {{
      network.body.data.edges.update({{ id: id, hidden: false }});
    }});

    network.fit();
  }}

  // ì²˜ìŒ ê²€ìƒ‰í•´ì„œ í¬ì»¤ìŠ¤í•  ë…¸ë“œê°€ ìˆëŠ” ê²½ìš°
  var initial = {focus_node_json};
  if (initial) {{
    setTimeout(function() {{
      try {{
        network.selectNodes([initial]);
        showOnlyConnected(initial);
      }} catch (e) {{}}
    }}, 600);
  }}

  // âœ… í´ë¦­ í•¸ë“¤ëŸ¬ ë“±ë¡
  network.on("click", function(params) {{
    if (params.nodes && params.nodes.length > 0) {{
      var nid = params.nodes[0];
      var m = (window.nodeMeta || {{}})[nid] || {{}};
      var sims = m["similar"] || [];

      var simsHtml = "";
      if (sims.length > 0) {{
        simsHtml = "<hr><div><b>ë¹„ìŠ·í•œ ì‚¬ëŒ TOP3</b><ol style='padding-left:18px; margin:4px 0;'>";
        for (var i = 0; i < sims.length; i++) {{
          var s = sims[i];
          var label = (s.name || "") + (s.ldap ? " (" + s.ldap + ")" : "");
          var reasonTxt = s.reasons ? " - " + s.reasons + " ì¼ì¹˜" : "";
          simsHtml += "<li>" + label + " (ì¡°ê±´ " + (s.score || 0) + "ê°œ ì¼ì¹˜" + reasonTxt + ")</li>";
        }}
        simsHtml += "</ol></div>";
      }}

      panel.innerHTML =
        "<h3 style='margin:0 0 6px 0;'>" + (m["ì´ë¦„"] || nid) + "</h3>" +
        "<div><b>ldap</b>: " + (m["ldap"] || "") + "</div>" +
        "<div><b>ì†Œì†</b>: " + (m["ì†Œì†"] || "") + "</div>" +
        "<div><b>ì§ìœ„</b>: " + (m["ì§ìœ„"] || "") + "</div>" +
        "<div><b>ì§êµ°</b>: " + (m["ì§êµ°"] || "") + "</div>" +
        "<div><b>ì…ì‚¬ë…„ë„</b>: " + (m["ì…ì‚¬ë…„ë„"] || "") + "</div>" +
        "<div><b>MBTI</b>: " + (m["MBTI"] || "") + "</div>" +
        "<div><b>í˜ˆì•¡í˜•</b>: " + (m["í˜ˆì•¡í˜•"] || "") + "</div>" +
        "<div><b>ë™ê¸° ì—¬ë¶€</b>: " + (m["ë™ê¸° ì—¬ë¶€"] || "") + "</div>" +
        "<hr>" +
        "<div><b>ì—°ê²° ìˆ˜</b>: " + (m["ì—°ê²° ìˆ˜"] || 0) + "</div>" +
        "<div><b>ê°™ì€ ì†Œì† ì¸ì›</b>: " + (m["ê°™ì€ ì†Œì† ìˆ˜"] || 0) + "</div>" +
        "<div><b>ê°™ì€ MBTI ì¸ì›</b>: " + (m["ê°™ì€ MBTI ìˆ˜"] || 0) + "</div>" +
        "<div><b>ê°™ì€ ë™ê¸° ì¸ì›</b>: " + (m["ê°™ì€ ë™ê¸° ìˆ˜"] || 0) + "</div>" +
        simsHtml +
        "<hr><small>ì´ ë…¸ë“œì™€ ì—°ê²°ëœ ê´€ê³„ë§Œ í‘œì‹œë©ë‹ˆë‹¤. ë¹ˆ ê³µê°„ì„ í´ë¦­í•˜ë©´ ì „ì²´ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ì‹œ ë³´ì…ë‹ˆë‹¤.</small>";

      // ğŸ”¥ ì‹¤ì œë¡œ ì—°ê²°ëœ ë…¸ë“œë§Œ ë‚¨ê¸°ê¸°
      showOnlyConnected(nid);

    }} else {{
      resetAll();
      panel.innerHTML =
        "<b>ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</b><br>" +
        "<small>ë¹ˆ ê³µê°„ì„ í´ë¦­í•˜ë©´ ì „ì²´ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ì‹œ ë³´ì…ë‹ˆë‹¤.</small>";
    }}
  }});
}})();
</script>
"""


# JS â†’ HTML ì‚½ì…
html_src = html_src.replace("</body>", panel_js + "\n</body>")
# html(html_src, height=820, scrolling=True)

# ==========================================
# ğŸŸ© ì—£ì§€ ìƒ‰ìƒ Legend (ë„¤íŠ¸ì›Œí¬ ìœ„ì— ë³´ì—¬ì¤Œ)
# ==========================================

legend_html = """
<div style="
    position:relative;
    top:0;
    padding:10px;
    margin-bottom:10px;
    background:#f3f4f6;
    border-radius:8px;
    font-size:13px;
    border:1px solid #e5e7eb;
">
<b>ğŸ¨ ì—£ì§€ ìƒ‰ìƒ ì˜ë¯¸</b><br>
ì†Œì† <span style='color:#22c55e;'>â– â– </span> /
ì§ìœ„ <span style='color:#16a34a;'>â– â– </span> /
íƒ„ìƒë…„ë„ <span style='color:#0ea5e9;'>â– â– </span> /
ë™ê¸° <span style='color:#3b82f6;'>â– â– </span> /
ì¹´ì¹´ì˜¤ <span style='color:#f59e0b;'>â– â– </span> /
ì„±ë³„ <span style='color:#ec4899;'>â– â– </span> /
ì…ì‚¬ë…„ë„ <span style='color:#a855f7;'>â– â– </span> /
MBTI <span style='color:#ef4444;'>â– â– </span> /
í˜ˆì•¡í˜• <span style='color:#f97316;'>â– â– </span>
<br>
<small>ì„ ì´ ë‘êº¼ìš¸ìˆ˜ë¡ ì¡°ê±´ì´ ë§ì´ ê²¹ì¹©ë‹ˆë‹¤.</small>
</div>
"""

st.markdown(legend_html, unsafe_allow_html=True)

# ==========================================
# ğŸ“¡ ë„¤íŠ¸ì›Œí¬ ì¶œë ¥
# ==========================================

html(html_src, height=820, scrolling=True)

# ì´ë¯¸ì§€ ëˆ„ë½ í‘œì‹œ
if MISSING_IMAGES:
    st.sidebar.markdown("### â— ëˆ„ë½ëœ ì´ë¯¸ì§€")
    for msg in sorted(MISSING_IMAGES):
        st.sidebar.write(msg)


# ==========================================
# ğŸ“Š Helper: bar chart with labels
# ==========================================

import matplotlib.pyplot as plt

def plot_bar_with_labels(data, title, xlabel="", ylabel="", color="#6366F1"):
    """
    data: pandas Series (index = label, values = ìˆ«ì)
    color: ë§‰ëŒ€ ìƒ‰ (ê¸°ë³¸ ì¸ë””ê³ )
    """
    fig, ax = plt.subplots()
    bars = ax.bar(data.index.astype(str), data.values, color=color)

    # ë ˆì´ë¸” ì¶”ê°€
    for bar in bars:
        yval = bar.get_height()
        ax.text(
            bar.get_x() + bar.get_width() / 2,
            yval,
            f"{yval:.0f}",
            ha="center",
            va="bottom",
            fontsize=9,
        )

    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    ax.grid(axis="y", alpha=0.2, linestyle="--")
    plt.xticks(rotation=45)
    plt.tight_layout()
    return fig



# ==========================================
# ğŸ“Œ ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„± ë¶„ì„ (Degree / Betweenness / Closeness / Eigenvector)
# ==========================================
with st.expander("ğŸ“Œ ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„± ë¶„ì„ (Degree / Betweenness / Closeness / Eigenvector)"):
    if G.number_of_nodes() == 0:
        st.info("ê·¸ë˜í”„ì— ë…¸ë“œê°€ ì—†ì–´ ì¤‘ì‹¬ì„±ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ì¤‘ì‹¬ì„± ê³„ì‚°
        degree_c = nx.degree_centrality(G)
        betweenness_c = nx.betweenness_centrality(G, normalized=True)
        closeness_c = nx.closeness_centrality(G)
        try:
            eigen_c = nx.eigenvector_centrality(G, max_iter=1000)
        except nx.PowerIterationFailedConvergence:
            eigen_c = {n: float("nan") for n in G.nodes()}

        rows = []
        for nid in G.nodes():
            row = df[df["node_id"] == nid].iloc[0]
            rows.append(
                {
                    "ì´ë¦„": row.get("ì´ë¦„", nid),
                    "ì†Œì†": row.get("ì†Œì†", ""),
                    "Degree": degree_c.get(nid, 0.0),
                    "Betweenness": betweenness_c.get(nid, 0.0),
                    "Closeness": closeness_c.get(nid, 0.0),
                    "Eigenvector": eigen_c.get(nid, 0.0),
                }
            )

        centrality_df = pd.DataFrame(rows).set_index("ì´ë¦„")

        st.markdown("**ì¤‘ì‹¬ì„± Top 5 (Eigenvector ê¸°ì¤€)**")
        # ìˆ«ì ì»¬ëŸ¼ë§Œ í¬ë§· ì ìš©
        num_cols = ["Degree", "Betweenness", "Closeness", "Eigenvector"]

        top5 = centrality_df.sort_values("Eigenvector", ascending=False).head(5)
        top5_style = top5.style.format("{:.3f}", subset=num_cols)

        st.dataframe(top5_style)

        metric = st.selectbox(
            "ì‹œê°í™”í•  ì§€í‘œ ì„ íƒ",
            ["Degree", "Betweenness", "Closeness", "Eigenvector"],
            index=3,
        )

        fig_c = plot_bar_with_labels(
            centrality_df.sort_values(metric, ascending=False)[metric].head(15),
            f"{metric} ìƒìœ„ 15ëª…",
            ylabel="ê°’",
        )
        st.pyplot(fig_c)


# ==========================================
# ğŸ“Š MBTI & ì…ì‚¬ë…„ë„ ë¶„í¬ + ì „ì²´ I/E, T/F ë¹„ìœ¨ + ì†Œì†ë³„ MBTI ë¹„ìœ¨
# ==========================================

with st.expander("ğŸ“Š MBTI / ì…ì‚¬ë…„ë„ ë¶„í¬ ì°¨íŠ¸"):
    col1, col2 = st.columns(2)

    # ---------------------------
    # âœ… ì „ì²´ MBTI ë¶„í¬ (ë°ì´í„°ë¶„ì„ë© í¬í•¨)
    # ---------------------------
    mbti_series = df["MBTI"].dropna().astype(str).str.strip()
    mbti_series = mbti_series[mbti_series != ""]
    if not mbti_series.empty:
        # ğŸ”¹ ë§ì´ ë‚˜ì˜¨ ìˆœìœ¼ë¡œ ì •ë ¬
        mbti_counts = mbti_series.value_counts().sort_values(ascending=False)
        col1.markdown("**MBTI ë¶„í¬**")
        fig = plot_bar_with_labels(
            mbti_counts,
            "MBTI ë¶„í¬",
            ylabel="ëª…",
            color="#6366F1",  # ì¸ë””ê³ 
        )
        col1.pyplot(fig)
    else:
        col1.info("MBTI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ---------------------------
    # âœ… ì „ì²´ ì…ì‚¬ë…„ë„ ë¶„í¬ (ë°ì´í„°ë¶„ì„ë© í¬í•¨)
    # ---------------------------
    if "ì…ì‚¬ë…„ë„" in df.columns:
        years = df["ì…ì‚¬ë…„ë„"].apply(extract_year).dropna().astype(int)

        if not years.empty:
            year_counts = years.value_counts().sort_index()
            col2.markdown("**ì…ì‚¬ë…„ë„ ë¶„í¬ (ì •ê·œí™”)**")
            fig2 = plot_bar_with_labels(
                year_counts,
                "ì…ì‚¬ë…„ë„ ë¶„í¬",
                ylabel="ëª…",
                color="#22C55E",  # ì´ˆë¡
            )
            col2.pyplot(fig2)
        else:
            col2.info("ì…ì‚¬ë…„ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        col2.info("ì…ì‚¬ë…„ë„ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # -----------------------------------------
    st.markdown("---")
    st.markdown("### ğŸŒ ì „ì²´ MBTI I/E, T/F ë¹„ìœ¨ (íŒŒì´ì°¨íŠ¸) â€” *ë°ì´í„°ë¶„ì„ë© í¬í•¨*")
    # -----------------------------------------

    overall_mbti = df["MBTI"].dropna().astype(str).str.strip()
    overall_mbti = overall_mbti[(overall_mbti != "") & (~overall_mbti.str.contains(r"\?"))]

    if not overall_mbti.empty:
        overall_IE = overall_mbti.str[0]
        overall_TF = overall_mbti.str[2]

        p1, p2 = st.columns(2)

        # ì „ì²´ I/E ë¹„ìœ¨
        ie_counts = overall_IE.value_counts()
        count_I = int(ie_counts.get("I", 0))
        count_E = int(ie_counts.get("E", 0))

        if count_I + count_E > 0:
            fig_ie, ax_ie = plt.subplots()
            ax_ie.pie(
                [count_I, count_E],
                labels=[f"I ({count_I})", f"E ({count_E})"],
                autopct="%1.1f%%",
                startangle=90,
            )
            ax_ie.axis("equal")
            p1.markdown("**ì „ì²´ I/E ë¹„ìœ¨**")
            p1.pyplot(fig_ie)
        else:
            p1.info("I/E ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ì „ì²´ T/F ë¹„ìœ¨
        tf_counts = overall_TF.value_counts()
        count_T = int(tf_counts.get("T", 0))
        count_F = int(tf_counts.get("F", 0))

        if count_T + count_F > 0:
            fig_tf, ax_tf = plt.subplots()
            ax_tf.pie(
                [count_T, count_F],
                labels=[f"T ({count_T})", f"F ({count_F})"],
                autopct="%1.1f%%",
                startangle=90,
            )
            ax_tf.axis("equal")
            p2.markdown("**ì „ì²´ T/F ë¹„ìœ¨**")
            p2.pyplot(fig_tf)
        else:
            p2.info("T/F ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì „ì²´ MBTI ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ MBTI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # -----------------------------------------
    st.markdown("---")
    st.markdown("### ğŸ§¬ ì†Œì†ë³„ MBTI I/E, T/F ë¹„ìœ¨ (ë°ì´í„°ë¶„ì„ë© ì œì™¸)")
    # -----------------------------------------

    if "MBTI" in df.columns and "ì†Œì†" in df.columns:
        # MBTI + ì†Œì† ì •ì œ
        df_mbti = df[["ì†Œì†", "MBTI"]].dropna().copy()
        df_mbti["MBTI"] = df_mbti["MBTI"].astype(str).str.strip()

        # ìµœì†Œ 3ì, ? í¬í•¨ëœ ì• ë“¤ì€ ì œì™¸ (I?T? ê°™ì€ ê°’ë“¤)
        df_mbti = df_mbti[df_mbti["MBTI"].str.len() >= 3]
        df_mbti = df_mbti[~df_mbti["MBTI"].str.contains(r"\?")]

        # ğŸ”´ ì—¬ê¸°ì—ì„œë§Œ ë°ì´í„°ë¶„ì„ë© ì œì™¸
        df_mbti = df_mbti[df_mbti["ì†Œì†"] != "ë°ì´í„°ë¶„ì„ë©"]

        if not df_mbti.empty:
            df_mbti["IE"] = df_mbti["MBTI"].str[0]
            df_mbti["TF"] = df_mbti["MBTI"].str[2]

            col3, col4 = st.columns(2)

            # --- ì†Œì†ë³„ I/E ë¹„ìœ¨ (% - I ë¹„ìœ¨ ê¸°ì¤€) ---
            ie_counts = df_mbti.groupby(["ì†Œì†", "IE"]).size().unstack(fill_value=0)
            if "I" not in ie_counts.columns:
                ie_counts["I"] = 0
            if "E" not in ie_counts.columns:
                ie_counts["E"] = 0

            denom_ie = (ie_counts["I"] + ie_counts["E"]).replace(0, pd.NA)
            ie_ratio_I = (ie_counts["I"] / denom_ie).fillna(0) * 100

            col3.markdown("**ì†Œì†ë³„ I ë¹„ìœ¨ (%)**")
            fig3 = plot_bar_with_labels(ie_ratio_I, "ì†Œì†ë³„ I ë¹„ìœ¨ (%)", ylabel="%")
            col3.pyplot(fig3)

            # --- ì†Œì†ë³„ T/F ë¹„ìœ¨ (% - T ë¹„ìœ¨ ê¸°ì¤€) ---
            tf_counts = df_mbti.groupby(["ì†Œì†", "TF"]).size().unstack(fill_value=0)
            if "T" not in tf_counts.columns:
                tf_counts["T"] = 0
            if "F" not in tf_counts.columns:
                tf_counts["F"] = 0

            denom_tf = (tf_counts["T"] + tf_counts["F"]).replace(0, pd.NA)
            tf_ratio_T = (tf_counts["T"] / denom_tf).fillna(0) * 100

            col4.markdown("**ì†Œì†ë³„ T ë¹„ìœ¨ (%)**")
            fig4 = plot_bar_with_labels(tf_ratio_T, "ì†Œì†ë³„ T ë¹„ìœ¨ (%)", ylabel="%")
            col4.pyplot(fig4)
        else:
            st.info("ì†Œì†ë³„ MBTI ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë˜ëŠ” ëª¨ë‘ ë°ì´í„°ë¶„ì„ë©ì´ë¼ ì œì™¸ë¨)")
    else:
        st.info("`ì†Œì†` ë˜ëŠ” `MBTI` ì»¬ëŸ¼ì´ ì—†ì–´ ì†Œì†ë³„ ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ==========================================
# ğŸ§¬ MBTI ìš”ì†Œ ë¹„ìœ¨ ë§‰ëŒ€í˜• íˆíŠ¸ë§µ
# ==========================================
with st.expander("ğŸ§¬ MBTI ìš”ì†Œ ë¹„ìœ¨ íˆíŠ¸ë§µ (ë§‰ëŒ€í˜•)"):
    mbti_clean = df["MBTI"].dropna().astype(str).str.strip()
    mbti_clean = mbti_clean[
        (mbti_clean != "") & (~mbti_clean.str.contains(r"\?")) & (mbti_clean.str.len() >= 4)
    ]

    if mbti_clean.empty:
        st.info("ìœ íš¨í•œ MBTI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        pairs = {
            "I/E": ("I", "E", mbti_clean.str[0]),
            "N/S": ("N", "S", mbti_clean.str[1]),
            "T/F": ("T", "F", mbti_clean.str[2]),
            "J/P": ("J", "P", mbti_clean.str[3]),
        }

        fig, ax = plt.subplots(figsize=(8, 6))
        y_labels = []
        left_bars = []
        right_bars = []
        left_labels = []
        right_labels = []

        for idx, (label, (left_key, right_key, series)) in enumerate(pairs.items()):
            counts = series.value_counts()
            total = counts.get(left_key, 0) + counts.get(right_key, 0)
            if total == 0:
                left_pct, right_pct = 0, 0
            else:
                left_pct = counts.get(left_key, 0) / total * 100
                right_pct = counts.get(right_key, 0) / total * 100

            y_labels.append(label)
            left_bars.append(left_pct)
            right_bars.append(right_pct)
            left_labels.append(f"{left_pct:.1f}%")
            right_labels.append(f"{right_pct:.1f}%")

        y_pos = np.arange(len(y_labels))

        # ì™¼ìª½ ë°” (ì²« ê¸€ì)
        ax.barh(y_pos, left_bars, color="#4ade80", label="ì²« ê¸€ì")  # ì´ˆë¡ ê³„ì—´
        # ì˜¤ë¥¸ìª½ ë°” (ë‘˜ì§¸ ê¸€ì)
        ax.barh(y_pos, right_bars, left=left_bars, color="#60a5fa", label="ë‘˜ì§¸ ê¸€ì")  # íŒŒë‘ ê³„ì—´

        # ë¼ë²¨(ìˆ˜ì¹˜) í‘œì‹œ
        for i in range(len(y_labels)):
            ax.text(left_bars[i] / 2, i, left_labels[i], va="center", ha="center", color="black")
            ax.text(left_bars[i] + right_bars[i] / 2, i, right_labels[i], va="center", ha="center", color="black")

        ax.set_yticks(y_pos)
        ax.set_yticklabels(y_labels)
        ax.set_xlabel("ë¹„ìœ¨ (%)")
        ax.set_title("MBTI ìš”ì†Œ ë¹„ìœ¨ ë§‰ëŒ€í˜• íˆíŠ¸ë§µ")

        ax.legend(loc="lower right")
        plt.tight_layout()
        st.pyplot(fig)



# ==========================================
# ğŸŒˆ ì†Œì†ë³„ MBTI ë‹¤ì–‘ì„± ì§€ìˆ˜ (Shannon entropy)
# ==========================================
with st.expander("ğŸŒˆ ì†Œì†ë³„ MBTI ë‹¤ì–‘ì„± ì§€ìˆ˜"):
    if "ì†Œì†" not in df.columns or "MBTI" not in df.columns:
        st.info("`ì†Œì†` ë˜ëŠ” `MBTI` ì»¬ëŸ¼ì´ ì—†ì–´ ë‹¤ì–‘ì„± ì§€ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        tmp = df[["ì†Œì†", "MBTI"]].dropna().copy()
        tmp["MBTI"] = tmp["MBTI"].astype(str).str.strip()
        tmp = tmp[
            (tmp["MBTI"] != "") & (~tmp["MBTI"].str.contains(r"\?")) & (tmp["MBTI"].str.len() >= 4)
        ]

        # ğŸ”´ ë°ì´í„°ë¶„ì„ë© ì œì™¸
        tmp = tmp[tmp["ì†Œì†"] != "ë°ì´í„°ë¶„ì„ë©"]

        if tmp.empty:
            st.info("ìœ íš¨í•œ MBTI ë°ì´í„°ê°€ ì—†ì–´ ë‹¤ì–‘ì„± ì§€ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            def shannon_entropy(series: pd.Series) -> float:
                counts = series.value_counts()
                p = counts / counts.sum()
                return float(-(p * np.log2(p)).sum())

            diversity = tmp.groupby("ì†Œì†")["MBTI"].apply(shannon_entropy)

            st.markdown("ê°’ì´ í´ìˆ˜ë¡ MBTI êµ¬ì„±ì´ ë‹¤ì–‘í•œ íŒ€ì…ë‹ˆë‹¤. (ë°ì´í„°ë¶„ì„ë© ì œì™¸)")
            fig_div = plot_bar_with_labels(
                diversity.sort_values(ascending=False),
                "ì†Œì†ë³„ MBTI ë‹¤ì–‘ì„± ì§€ìˆ˜ (Shannon entropy)",
                ylabel="Entropy",
                color="#0EA5E9",  # í•˜ëŠ˜ìƒ‰
            )
            st.pyplot(fig_div)


# ==========================================
# ğŸ‘¶ ì„¸ëŒ€ êµ¬ì„± ê·¸ë˜í”„
# ==========================================
with st.expander("ğŸ‘¶ ì„¸ëŒ€ êµ¬ì„± ê·¸ë˜í”„"):
    if "íƒ„ìƒë…„ë„_Y" not in df.columns:
        st.info("ì •ê·œí™”ëœ íƒ„ìƒë…„ë„(`íƒ„ìƒë…„ë„_Y`)ê°€ ì—†ì–´ ì„¸ëŒ€ êµ¬ì„±ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        gen_series = df["íƒ„ìƒë…„ë„_Y"].apply(generation_from_year)
        gen_series = gen_series.dropna()

        if gen_series.empty:
            st.info("ì„¸ëŒ€ ì •ë³´ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ì „ì²´ ì„¸ëŒ€ ë¶„í¬
            counts = gen_series.value_counts()
            fig_g, ax_g = plt.subplots()
            ax_g.pie(
                counts.values,
                labels=[f"{k} ({v})" for k, v in counts.items()],
                autopct="%1.1f%%",
                startangle=90,
            )
            ax_g.axis("equal")
            st.markdown("**ì „ì²´ ì„¸ëŒ€ ë¶„í¬**")
            st.pyplot(fig_g)

            # ì†Œì†ë³„ ì„¸ëŒ€ ë¶„í¬ (ë¹„ìœ¨)  ğŸ‘‰ ë°ì´í„°ë¶„ì„ë© ì œì™¸
            if "ì†Œì†" in df.columns:
                tmp = pd.DataFrame({"ì†Œì†": df["ì†Œì†"], "ì„¸ëŒ€": gen_series}).dropna()

                # ğŸ”´ ë°ì´í„°ë¶„ì„ë© ì œì™¸
                tmp = tmp[tmp["ì†Œì†"] != "ë°ì´í„°ë¶„ì„ë©"]

                if not tmp.empty:
                    pivot = (
                        tmp.groupby(["ì†Œì†", "ì„¸ëŒ€"]).size().unstack(fill_value=0)
                    )
                    pivot_pct = pivot.div(pivot.sum(axis=1), axis=0) * 100

                    st.markdown("**ì†Œì†ë³„ ì„¸ëŒ€ ë¹„ìœ¨ (%) (ë°ì´í„°ë¶„ì„ë© ì œì™¸)**")
                    fig_g2, ax_g2 = plt.subplots()
                    bottom = np.zeros(len(pivot_pct))
                    x = np.arange(len(pivot_pct.index))

                    for gen in pivot_pct.columns:
                        vals = pivot_pct[gen].values
                        ax_g2.bar(x, vals, bottom=bottom, label=gen)
                        bottom += vals

                    ax_g2.set_xticks(x)
                    ax_g2.set_xticklabels(pivot_pct.index, rotation=45, ha="right")
                    ax_g2.set_ylabel("%")
                    ax_g2.set_title("ì†Œì†ë³„ ì„¸ëŒ€ ë¹„ìœ¨ (Stacked)")
                    ax_g2.legend(title="ì„¸ëŒ€")
                    plt.tight_layout()
                    st.pyplot(fig_g2)
                else:
                    st.info("ë°ì´í„°ë¶„ì„ë©ì„ ì œì™¸í•˜ê³ ëŠ” ì„¸ëŒ€ ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")



# ==========================================
# ğŸ¤ íŒ€ ì¼€ë¯¸ ë¶„ì„ (similar_map ê¸°ë°˜)
# ==========================================
with st.expander("ğŸ¤ íŒ€ ì¼€ë¯¸ ë¶„ì„"):
    # ldap -> node_id ë§¤í•‘
    ldap_to_nid = {}
    for _, r in df.iterrows():
        ldap_val = str(r.get("ldap", "") or "").strip()
        if ldap_val:
            ldap_to_nid[ldap_val] = r["node_id"]

    pair_dict = {}
    for nid, lst in similar_map.items():
        for s in lst:
            other_ldap = str(s.get("ldap", "") or "").strip()
            other_nid = ldap_to_nid.get(other_ldap)
            if not other_nid:
                continue
            key = tuple(sorted([nid, other_nid]))
            cur = pair_dict.get(key)
            if (cur is None) or (s["score"] > cur["score"]):
                pair_dict[key] = {
                    "A_id": key[0],
                    "B_id": key[1],
                    "score": s["score"],
                    "reasons": s.get("reasons", ""),
                }

    if not pair_dict:
        st.info("í˜„ì¬ ì„¤ì •ëœ ì—£ì§€ ê¸°ì¤€ìœ¼ë¡œ ì¼€ë¯¸ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìŒì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        rows = []
        for key, val in pair_dict.items():
            a_row = df[df["node_id"] == val["A_id"]].iloc[0]
            b_row = df[df["node_id"] == val["B_id"]].iloc[0]
            rows.append(
                {
                    "A": f"{a_row.get('ì´ë¦„', '')} ({a_row.get('ldap', '')})",
                    "B": f"{b_row.get('ì´ë¦„', '')} ({b_row.get('ldap', '')})",
                    "ì¼€ë¯¸ ì ìˆ˜(ì¡°ê±´ ìˆ˜)": int(val["score"]),
                    "ê³µí†µ ì¡°ê±´": val["reasons"],
                }
            )

        pair_df = pd.DataFrame(rows).sort_values(
            "ì¼€ë¯¸ ì ìˆ˜(ì¡°ê±´ ìˆ˜)", ascending=False
        )

        st.markdown("**ì¼€ë¯¸ ìƒìœ„ TOP 10 ìŒ**")
        st.dataframe(pair_df.head(10))

        avg_score = pair_df["ì¼€ë¯¸ ì ìˆ˜(ì¡°ê±´ ìˆ˜)"].mean()
        max_score = pair_df["ì¼€ë¯¸ ì ìˆ˜(ì¡°ê±´ ìˆ˜)"].max()
        st.markdown(
            f"- ì „ì²´ í‰ê·  ì¼€ë¯¸ ì ìˆ˜: **{avg_score:.2f}**  (ìµœëŒ€ {max_score} ì¡°ê±´ ì¼ì¹˜)\n"
            f"- ì´ ì¼€ë¯¸ ìŒ ìˆ˜: **{len(pair_df)}**"
        )

        # ì¼€ë¯¸ ì ìˆ˜ ë¶„í¬
        fig_k = plot_bar_with_labels(
            pair_df["ì¼€ë¯¸ ì ìˆ˜(ì¡°ê±´ ìˆ˜)"].value_counts().sort_index(),
            "ì¼€ë¯¸ ì ìˆ˜ ë¶„í¬ (ì¡°ê±´ ì¼ì¹˜ ê°œìˆ˜)",
            ylabel="ìŒ ìˆ˜",
        )
        st.pyplot(fig_k)



# ==========================================
# ğŸ–¼ í¬ìŠ¤í„° ë·° (íŒ€ êµ¬ì„±ë„ ì¸ì‡„ìš© ë ˆì´ì•„ì›ƒ)
# ==========================================

with st.expander("ğŸ–¼ íŒ€ êµ¬ì„±ë„ í¬ìŠ¤í„° ë·° (ì†Œì†ë³„ ì •ë ¬)"):
    st.markdown("PDFë¡œ ì €ì¥í•˜ë©´ í¬ìŠ¤í„°ì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”!")

    # ì›í•˜ëŠ” ì†Œì† ìˆœì„œ
    dept_order = ["ë°ì´í„°ë¶„ì„ë©", "BIì…€", "ë°ì´í„°í…Œí¬ì…€", "ì´ìƒíƒì§€ì…€"]

    # ì†Œì†ë³„ ê·¸ë£¹
    grouped = df.groupby("ì†Œì†")

    # 1) ìš°ë¦¬ê°€ ì§€ì •í•œ ìˆœì„œëŒ€ë¡œ ë¨¼ì € ì¶œë ¥
    for dept in dept_order:
        if dept not in grouped.groups:
            continue  # í•´ë‹¹ ì†Œì†ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°

        group = grouped.get_group(dept)
        st.markdown(f"## ğŸ“Œ {dept}")
        cols = st.columns(4)

        for idx, (_, r) in enumerate(group.iterrows()):
            col = cols[idx % 4]
            img = resolve_image(r)

            if img:
                col.image(img, width=120)

            jy = extract_year(r.get("ì…ì‚¬ë…„ë„"))
            col.markdown(
                f"**{r.get('ì´ë¦„','')}**  \n"
                f"{r.get('ì§ìœ„','')}  \n"
                f"{jy or ''} ì…ì‚¬ Â· {r.get('MBTI','')}"
            )

    # 2) ë§Œì•½ ë‹¤ë¥¸ ì†Œì†ì´ ë” ìˆë‹¤ë©´, ë‚˜ë¨¸ì§€ëŠ” ì´ë¦„ìˆœ/ì‚¬ì „ìˆœìœ¼ë¡œ ë’¤ì— ì¶œë ¥
    other_depts = [d for d in grouped.groups.keys() if d not in dept_order]

    for dept in sorted(other_depts):
        group = grouped.get_group(dept)
        st.markdown(f"## ğŸ“Œ {dept}")
        cols = st.columns(4)

        for idx, (_, r) in enumerate(group.iterrows()):
            col = cols[idx % 4]
            img = resolve_image(r)

            if img:
                col.image(img, width=120)

            jy = extract_year(r.get("ì…ì‚¬ë…„ë„"))
            col.markdown(
                f"**{r.get('ì´ë¦„','')}**  \n"
                f"{r.get('ì§ìœ„','')}  \n"
                f"{jy or ''} ì…ì‚¬ Â· {r.get('MBTI','')}"
            )


# ==========================================
# ğŸ“‘ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
# ==========================================

with st.expander("ğŸ“‘ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (í•„í„° ì ìš©)"):
    st.dataframe(df_vis)



# ==========================================
# ğŸ¤– AI ê¸°ëŠ¥ 5ì¢… (OpenAI í…ìŠ¤íŠ¸ ëª¨ë¸ ì‚¬ìš©)
# ==========================================

# ------------------------------------------
# 1) íŒ€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ìš”ì•½
# ------------------------------------------
def ai_team_network_summary(G, df):
    summary_prompt = f"""
You are an expert organization analyst.

Analyze the following team network:

- Nodes: {len(G.nodes())}
- Edges: {len(G.edges())}
- Top degrees: {sorted([(n, d) for n, d in G.degree()], key=lambda x: -x[1])[:5]}

Also analyze:
- MBTI distribution
- Department composition
- Cross-department connection patterns

Return:
1) ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ ì¡°ì§ ë¶„ì„
2) íŒ€ ë¶„ìœ„ê¸°/êµ¬ì¡° íŠ¹ì§•
3) ê°œì„  ì œì•ˆ 3ê°€ì§€
4) ë§¤ë ¥ í¬ì¸íŠ¸ 3ê°€ì§€
"""

    resp = client.responses.create(
        model="gpt-4.1",
        input=summary_prompt
    )
    return resp.output_text


# ------------------------------------------
# 2) ê°œì¸ í”„ë¡œí•„ ê°•í™” ì„¤ëª…
# ------------------------------------------
def ai_rich_profile(row, similar_top3):
    prompt = f"""
You are generating a rich personality profile of the following team member:

ì´ë¦„: {row['ì´ë¦„']}
ì†Œì†: {row['ì†Œì†']}
ì§ìœ„: {row['ì§ìœ„']}
ì…ì‚¬ë…„ë„: {extract_year(row['ì…ì‚¬ë…„ë„'])}
MBTI: {row['MBTI']}
í˜ˆì•¡í˜•: {row['í˜ˆì•¡í˜•']}
ë™ê¸° ì—¬ë¶€: {row['ë™ê¸° ì—¬ë¶€']}
ì„±ë³„: {row['ì„±ë³„']}

ë¹„ìŠ·í•œ ì‚¬ëŒ TOP3:
{json.dumps(similar_top3, ensure_ascii=False)}

Write:
1) ì´ ì‚¬ëŒì˜ ë¶„ìœ„ê¸°/ì—…ë¬´ ìŠ¤íƒ€ì¼/ì¥ì 
2) MBTI ê¸°ë°˜ í•´ì„
3) íŒ€ ë‚´ ì—­í• ê³¼ ê°•ì 
4) TOP3 similarity ê¸°ë°˜ ì¸ê°„ê´€ê³„ ë¶„ì„
5) ë§ˆì§€ë§‰ì— í•œ ì¤„ ë³„ëª… ì¶”ì²œ
"""

    resp = client.responses.create(
        model="gpt-4.1",
        input=prompt
    )
    return resp.output_text


# ------------------------------------------
# 3) íŒ€ì› ê°„ ê¶í•© ë¶„ì„
# ------------------------------------------
def ai_chemistry(a_row, b_row):
    prompt = f"""
ë‘ íŒ€ì›ì˜ ê¶í•©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

A:
- ì´ë¦„: {a_row['ì´ë¦„']}
- ì†Œì†: {a_row['ì†Œì†']}
- ì§ìœ„: {a_row['ì§ìœ„']}
- MBTI: {a_row['MBTI']}

B:
- ì´ë¦„: {b_row['ì´ë¦„']}
- ì†Œì†: {b_row['ì†Œì†']}
- ì§ìœ„: {b_row['ì§ìœ„']}
- MBTI: {b_row['MBTI']}

Return:
1) ì „ì²´ ì¼€ë¯¸ ì ìˆ˜ (10ì  ê¸°ì¤€)
2) ì˜ ë§ëŠ” ì´ìœ 
3) ë¶€ë”ªí ìˆ˜ ìˆëŠ” ë¶€ë¶„
4) í˜‘ì—… ì‹œ íŒ 3ê°€ì§€
5) í•´ì„ ìŠ¤íƒ€ì¼ì€ â€œí”„ë¡œ ë¦¬ë”ì˜ ê´€ì°°ì¼ì§€â€ ëŠë‚Œ
"""

    resp = client.responses.create(
        model="gpt-4.1",
        input=prompt
    )
    return resp.output_text


# ------------------------------------------
# 4) íŒ€ ìŠ¬ë¡œê±´ ìƒì„±
# ------------------------------------------
def ai_team_slogans(df):
    members = ", ".join(df["ì´ë¦„"].tolist())

    prompt = f"""
íŒ€ êµ¬ì„±ì›: {members}

ë°ì´í„°ë¶„ì„ë© & ê° ì…€(BIì…€, ë°ì´í„°í…Œí¬ì…€, ì´ìƒíƒì§€ì…€)ì˜ íŒ€ ìŠ¬ë¡œê±´ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ìŠ¬ë¡œê±´ ì¢…ë¥˜:
1) ê°ì„± ë²„ì „
2) ìœ ë¨¸ ë²„ì „
3) íˆì–´ë¡œ ì˜í™” í¬ìŠ¤í„° ë²„ì „
4) ì§§ê³  ê°„ê²°í•œ ìºì¹˜í”„ë ˆì´ì¦ˆ 5ê°œ
"""

    resp = client.responses.create(
        model="gpt-4.1",
        input=prompt
    )
    return resp.output_text


# ------------------------------------------
# 5) ì•„ì´ì²˜ëŸ¼ ì„¤ëª…í•œ ì…€ ì†Œê°œ
# ------------------------------------------
def ai_childlike_cell_intro(df):
    dept_groups = df.groupby("ì†Œì†").size().to_dict()

    prompt = f"""
ê° ì…€ êµ¬ì„± ì¸ì› ìˆ˜:
{json.dumps(dept_groups, ensure_ascii=False)}

ê° ì…€ì„ "5ì‚´ ì–´ë¦°ì´ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´" ê·€ì—½ê³  ë‹¨ìˆœí•˜ê²Œ ì†Œê°œí•´ì¤˜.
ê° ì…€ë§ˆë‹¤:
- ì–´ë–¤ ì—­í• ì„ í•˜ëŠ” ê³³ì¸ì§€
- ì–´ë–¤ ì‚¬ëŒë“¤ì´ ìˆëŠ”ì§€
- ë™ë¬¼ë¡œ ë¹„ìœ í•˜ë©´ ì–´ë–¤ ëŠë‚Œì¸ì§€
"""

    resp = client.responses.create(
        model="gpt-4.1",
        input=prompt,
    )
    return resp.output_text


# ==========================================
# ğŸ› AI ë¶„ì„ ë„êµ¬ UI (ë©”ì¸ í˜ì´ì§€ ì•„ë˜)
# ==========================================

st.markdown("---")
st.header("ğŸ”® AI ë¶„ì„ ë„êµ¬")

ai_tabs = st.tabs([
    "ğŸ“¡ íŒ€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„",
    "ğŸ§  ê°œì¸ í”„ë¡œí•„ AI í•´ì„",
    "ğŸ’ íŒ€ì› ê¶í•© ë¶„ì„",
    "âš¡ íŒ€ ìŠ¬ë¡œê±´ ìƒì„±",
    "ğŸ‘¶ ì•„ì´ì²˜ëŸ¼ ì„¤ëª…í•œ ì…€ ì†Œê°œ"
])


# ------------------------------------------
# ğŸ“¡ 1) íŒ€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ìš”ì•½
# ------------------------------------------
with ai_tabs[0]:
    st.subheader("ğŸ“¡ íŒ€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ìš”ì•½")

    if st.button("AI ë¶„ì„ ìƒì„±", key="btn_net_summary"):
        with st.spinner("AIê°€ íŒ€ ë„¤íŠ¸ì›Œí¬ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
            try:
                summary = ai_team_network_summary(G, df)
                st.markdown(summary)
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")


# ------------------------------------------
# ğŸ§  2) ê°œì¸ í”„ë¡œí•„ AI í•´ì„
# ------------------------------------------
with ai_tabs[1]:
    st.subheader("ğŸ§  ê°œì¸ í”„ë¡œí•„ AI í•´ì„")

    target = st.selectbox("íŒ€ì› ì„ íƒ", df["ì´ë¦„"].unique(), key="profile_select")

    if st.button("AI í”„ë¡œí•„ ìƒì„±", key="btn_profile"):
        row = df[df["ì´ë¦„"] == target].iloc[0]
        nid = row["node_id"]
        similar3 = similar_map.get(nid, [])

        with st.spinner("AIê°€ í”„ë¡œí•„ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            try:
                profile = ai_rich_profile(row, similar3)
                st.markdown(profile)
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")


# ------------------------------------------
# ğŸ’ 3) íŒ€ì› ê¶í•© ë¶„ì„
# ------------------------------------------
with ai_tabs[2]:
    st.subheader("ğŸ’ íŒ€ì› ê°„ ê¶í•© ë¶„ì„")

    colA, colB = st.columns(2)
    name_a = colA.selectbox("A íŒ€ì›", df["ì´ë¦„"].unique(), key="chem_a")
    name_b = colB.selectbox("B íŒ€ì›", df["ì´ë¦„"].unique(), key="chem_b")

    if st.button("ê¶í•© ë¶„ì„í•˜ê¸°", key="btn_chem"):
        if name_a == name_b:
            st.warning("ì„œë¡œ ë‹¤ë¥¸ íŒ€ì›ì„ ì„ íƒí•´ì£¼ì„¸ìš”!")
        else:
            a_row = df[df["ì´ë¦„"] == name_a].iloc[0]
            b_row = df[df["ì´ë¦„"] == name_b].iloc[0]

            with st.spinner("AIê°€ ê¶í•© ë¶„ì„ ì¤‘..."):
                try:
                    result = ai_chemistry(a_row, b_row)
                    st.markdown(result)
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")


# ------------------------------------------
# âš¡ 4) íŒ€ ìŠ¬ë¡œê±´ ìƒì„±
# ------------------------------------------
with ai_tabs[3]:
    st.subheader("âš¡ íŒ€ ìŠ¬ë¡œê±´ ë§Œë“¤ê¸°")

    if st.button("ìŠ¬ë¡œê±´ ìë™ ìƒì„±", key="btn_slogan"):
        with st.spinner("AIê°€ ìŠ¬ë¡œê±´ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            try:
                result = ai_team_slogans(df)
                st.markdown(result)
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")


# ------------------------------------------
# ğŸ‘¶ 5) ì•„ì´ì²˜ëŸ¼ ì„¤ëª…í•œ ì…€ ì†Œê°œ
# ------------------------------------------
with ai_tabs[4]:
    st.subheader("ğŸ‘¶ ì•„ì´ì²˜ëŸ¼ ì„¤ëª…í•œ ì…€ ì†Œê°œ")

    if st.button("ì…€ ì†Œê°œ ìƒì„±í•˜ê¸°", key="btn_childlike"):
        with st.spinner("AIê°€ ê·€ì—¬ìš´ ì„¤ëª… ìƒì„± ì¤‘..."):
            try:
                result = ai_childlike_cell_intro(df)
                st.markdown(result)
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
