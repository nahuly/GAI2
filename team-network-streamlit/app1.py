# app.py (Streamlit + PyVis)
# ìš°ë¦¬íŒ€ ì¸ì  ë„¤íŠ¸ì›Œí¬ â€” ì—…ë°ì´íŠ¸: ì´ë¯¸ì§€ ë§¤ì¹­/ì—°ë„ íŒŒì‹±/í•„í„°/ì§„ë‹¨ ê°œì„ 
#
# ì‹¤í–‰:
#   streamlit run app.py
#
# ì˜ì¡´ì„±:
#   pip install streamlit pyvis networkx pandas matplotlib

import os, io, json, base64, re
import pandas as pd
import streamlit as st
from streamlit.components.v1 import html
import networkx as nx
from pyvis.network import Network
import matplotlib.pyplot as plt
from openai import OpenAI
import os

# Streamlit secretsì— ì €ì¥í–ˆë‹¤ëŠ” ê°€ì • (ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì“°ë©´ ê·¸ê±¸ë¡œ ë°”ê¿”ë„ OK)
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
# í™˜ê²½ë³€ìˆ˜ë¼ë©´ ì´ë ‡ê²Œ:
# openai.api_key = os.environ.get("OPENAI_API_KEY", "")

# ---------------- ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(page_title="ìš°ë¦¬íŒ€ ì¸ì  ë„¤íŠ¸ì›Œí¬", layout="wide")
st.title("ğŸ•¸ï¸ ë°ì´í„°ë¶„ì„ë© ì¸ì  ë„¤íŠ¸ì›Œí¬")

st.markdown(
    """
- MBTI ê¸°ë°˜ ì¸ì  ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”  
- ê³µí†µ ì†ì„±(ì†Œì†, íƒ„ìƒë…„ë„, MBTI, í˜ˆì•¡í˜• ë“±)ìœ¼ë¡œ ê°„ì„  ìƒì„±  
- ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ í”„ë¡œí•„ / ì—°ê²° í†µê³„ / ë¹„ìŠ·í•œ ì‚¬ëŒ TOP3 í‘œì‹œ  
"""
)

# ---------------- Sidebar ----------------
st.sidebar.header("âš™ï¸ ì‹œê°í™” ì„¤ì •")
physics = st.sidebar.selectbox("ë¬¼ë¦¬ì—”ì§„", ["barnes_hut", "force_atlas_2based", "repulsion"], index=1)
base_node_size = st.sidebar.slider("ê¸°ë³¸ ë…¸ë“œ í¬ê¸°", 5, 60, 16)
degree_scale = st.sidebar.slider("ì°¨ìˆ˜ ê¸°ë°˜ í¬ê¸° ìŠ¤ì¼€ì¼", 0, 40, 5)
show_labels = st.sidebar.checkbox("ì´ë¦„ ë¼ë²¨ í‘œì‹œ", value=True)

st.sidebar.markdown("---")
st.sidebar.header("ğŸ” MBTI í•„í„°")
ei_filter = st.sidebar.selectbox("E/I í•„í„°", ["(ì „ì²´)", "Eë§Œ", "Ië§Œ"], index=0)
tf_filter = st.sidebar.selectbox("T/F í•„í„°", ["(ì „ì²´)", "Të§Œ", "Fë§Œ"], index=0)
mbti_exact_placeholder = st.sidebar.empty()  # ë‚˜ì¤‘ì— ì‹¤ì œ ì˜µì…˜ ì±„ì›€

# ğŸ§µ ì—£ì§€ íƒ€ì… í† ê¸€
st.sidebar.markdown("---")
st.sidebar.header("ğŸ§µ ì—£ì§€ íƒ€ì… í† ê¸€")

# ì „ì²´ í† ê¸€ (ì¼œë©´ ëª¨ë“  ì—£ì§€ íƒ€ì…ì„ ê°•ì œë¡œ ì‚¬ìš©)
show_edge_all      = st.sidebar.checkbox("ì „ì²´", value=False)

# ê¸°ë³¸ìœ¼ë¡œ ì¼œë‘˜ ê²ƒ: ì†Œì†, íƒ„ìƒë…„ë„, MBTI, í˜ˆì•¡í˜•
show_edge_dept     = st.sidebar.checkbox("ì†Œì†", value=True)
show_edge_role     = st.sidebar.checkbox("ì§ìœ„", value=False)
show_edge_birth    = st.sidebar.checkbox("íƒ„ìƒë…„ë„", value=True)
show_edge_cohort   = st.sidebar.checkbox("ë™ê¸°", value=False)
show_edge_kakao    = st.sidebar.checkbox("ì¹´ì¹´ì˜¤ ë¶„ì‚¬", value=False)
show_edge_sex      = st.sidebar.checkbox("ì„±ë³„", value=False)
show_edge_joinyear = st.sidebar.checkbox("ì…ì‚¬ë…„ë„", value=False)
show_edge_mbti     = st.sidebar.checkbox("MBTI", value=True)
show_edge_blood    = st.sidebar.checkbox("í˜ˆì•¡í˜•", value=True)

st.sidebar.markdown("---")
# ê²€ìƒ‰ ë°•ìŠ¤ë¥¼ ì´ ìœ„ì¹˜ì— ë„£ê¸° ìœ„í•´ placeholder ì‚¬ìš©
search_box_placeholder = st.sidebar.empty()

st.sidebar.markdown("---")
st.sidebar.header("ğŸ“„ ë°ì´í„° ì—…ë¡œë“œ")
uploaded_csv = st.sidebar.file_uploader("íŒ€ CSV ì—…ë¡œë“œ", type=["csv"])
uploaded_imgs = st.sidebar.file_uploader(
    "ë…¸ë“œ ì‚¬ì§„ ì—…ë¡œë“œ(ì„ íƒ, ì—¬ëŸ¬ ê°œ)", type=["png", "jpg", "jpeg"], accept_multiple_files=True
)

# ---------------- Default data ----------------
default_csv = """ì´ë¦„,ldap,ì†Œì†,ì§ìœ„,ì§êµ°,íƒ„ìƒë…„ë„,ì…ì‚¬ë…„ë„,MBTI,í˜ˆì•¡í˜•,ë™ê¸° ì—¬ë¶€,ì¹´ì¹´ì˜¤ë¶„ì‚¬,ì„±ë³„,ì›Œí¬ìƒµ ì„±í–¥(2022),ì›Œí¬ìƒµì„±í–¥(2025),ê±°ì£¼ì§€,ê²°í˜¼ì—¬ë¶€,Image
ê¹€ìˆ˜í˜•,cantabile.58,ë°ì´í„°ë¶„ì„ë©,ì‹¤ì¥,ê°œë°œ,1970,2015,INTP,O,,ì¹´ì¹´ì˜¤,ë‚¨ì,íë§,íë§,ê²½ê¸°ë„,ê¸°í˜¼,cantabile.png
ê¹€ì„ ì˜,party.92,BIì…€,ì…€ì¥,ê¸°ìˆ ,1984,2016,ESFJ,A,,ì¹´ì¹´ì˜¤,ì—¬ì,íë§,íë§,ê²½ê¸°ë„,ê¸°í˜¼,party.png
ì†¡ëŒ€ì„­,steven.song,BIì…€,ì…€ì›,ê°œë°œ,1989,2018.1.22,ISTP,O,,,ë‚¨ì,íë§,íë§,ê²½ê¸°ë„,ë¯¸í˜¼,steven.png
ì´ë‚˜ì—°,zoe.lee93,BIì…€,ì…€ì›,ê°œë°œ,1993,2022.1.17,INFJ,A,,,ì—¬ì,ì•¡í‹°ë¹„í‹°,íë§,ì„œìš¸,ë¯¸í˜¼,zoe.png
ìœ ì„ ì •,saylor.u,BIì…€,ì…€ì›,ê¸°ìˆ ,1994,2023.5.2,INFP,A,,,ì—¬ì,,ì•¡í‹°ë¹„í‹°,ê²½ê¸°ë„,ë¯¸í˜¼,saylor.png
ì¡°ìŠ¹ë¯¼,noah.94,BIì…€,ì…€ì›,ê¸°ìˆ ,1994,2024.10.28,ESFJ,A,2024 ê²½ë ¥ì§ ë™ê¸°,,ë‚¨ì,,ì•¡í‹°ë¹„í‹°,ê²½ê¸°ë„,ê¸°í˜¼,noah.png
ê¹€ìš©í™˜,feno.meno,BIì…€,ì…€ì›,ê°œë°œ,1994,2024.11.18,INFP,AB,2024 ê²½ë ¥ì§ ë™ê¸°,,ë‚¨ì,,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ë¯¸í˜¼,feno.png
ê°•ë™ì§„,sonny.kang,BIì…€,ì…€ì›,ê¸°ìˆ ,1995,2021.6.23,ESFP,A,2021 ì¸í„´ ë™ê¸°,,ë‚¨ì,ì•¡í‹°ë¹„í‹°,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ë¯¸í˜¼,sonny.png
ì¡°ìœ¤ì˜,zoey.cho,BIì…€,ì…€ì›,ê°œë°œ,1996,2021.6.23,INTJ,B,2021 ì¸í„´ ë™ê¸°,,ì—¬ì,ì•¡í‹°ë¹„í‹°,íë§,ì„œìš¸,ê¸°í˜¼,zoey.png
ì¡°ì€í¬,alysia.c,ë°ì´í„°í…Œí¬ì…€,ì…€ì¥,ê°œë°œ,1980,2017,ISTP,A,,ì¹´ì¹´ì˜¤,ì—¬ì,íë§,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,alysia.png
ì •ë™ì£¼,dj.jeong,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1988,2017.3.20,ISFP,AB,,,ì—¬ì,íë§,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,dj.png
ìœ¤íƒœì‹,levi.y,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1992,2020.12.22,ENTJ,B,,,ë‚¨ì,ì•¡í‹°ë¹„í‹°,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,levi.png
ì´ì°½ìš±,carl.lee,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1993,2021.11.30,INTP,,2021 ê³µì±„ ë™ê¸°,,ë‚¨ì,íë§,ì•¡í‹°ë¹„í‹°,ê²½ê¸°ë„,ë¯¸í˜¼,carl.png
ê¹€ë²”ì¤€,breadly.abc,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1994,2024.11.18,ISFJ,O,2024 ê²½ë ¥ì§ ë™ê¸°,,ë‚¨ì,,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,breadly.png
ê¹€í¬ì›,wonnie.kim,ë°ì´í„°í…Œí¬ì…€,ì…€ì›,ê°œë°œ,1997,2021.6.23,ENFP,,2021 ì¸í„´ ë™ê¸°,,ì—¬ì,ì•¡í‹°ë¹„í‹°,íë§,ì„œìš¸,ë¯¸í˜¼,wonnie.png
ë°•ì¢…ë²”,jaybe.park,ì´ìƒíƒì§€ì…€,ì…€ì¥,ê°œë°œ,1990,2019,ESTP,A,,,ë‚¨ì,ì•¡í‹°ë¹„í‹°,ì•¡í‹°ë¹„í‹°,ì„œìš¸,ê¸°í˜¼,jaybe.png
ì£¼ì² ë¯¼,iron.min,ì´ìƒíƒì§€ì…€,ì…€ì›,ê°œë°œ,1988,2018.9.18,INFJ,B,,,ë‚¨ì,íë§,íë§,ê²½ê¸°ë„,ë¯¸í˜¼,iron.png
ê¹€ìš°ì˜,walt.kim,ì´ìƒíƒì§€ì…€,ì…€ì›,ê°œë°œ,1990,2020.11.24,,,,,ë‚¨ì,ì•¡í‹°ë¹„í‹°,íë§,ê²½ê¸°ë„,ë¯¸í˜¼,walt.png
ì´ì¢…ìš°,justin.dev,ì´ìƒíƒì§€ì…€,ì…€ì›,ê°œë°œ,1995,2021.11.17,INTJ,B,2021 ê³µì±„ ë™ê¸°,,ë‚¨ì,íë§,íë§,ê²½ê¸°ë„,ë¯¸í˜¼,justin.png
ê¹€í˜œì •,molly.ouo,ì´ìƒíƒì§€ì…€,ì…€ì›,ê°œë°œ,1999,2023.1.16,ENFJ,B,,,ì—¬ì,,íë§,ì„œìš¸,ë¯¸í˜¼,molly.png
"""

if uploaded_csv:
    df = pd.read_csv(uploaded_csv)
else:
    df = pd.read_csv(io.StringIO(default_csv))

# ì»¬ëŸ¼ ì´ë¦„ ê³µë°± ì œê±°/ì •ê·œí™”
df.columns = [c.strip() for c in df.columns]

# Image -> image í†µì¼
if "Image" in df.columns and "image" not in df.columns:
    df["image"] = df["Image"]

# ê°’ ê³µë°± ì œê±°
df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

# ---------------- ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ ----------------
IMG_DIR = "node_images"
os.makedirs(IMG_DIR, exist_ok=True)
if uploaded_imgs:
    for f in uploaded_imgs:
        with open(os.path.join(IMG_DIR, f.name), "wb") as out:
            out.write(f.read())

# ì´ë¯¸ì§€ ë§¤ì¹­ ê°œì„  + ì§„ë‹¨
def _variants(name: str):
    if not name:
        return []
    base, ext = os.path.splitext(str(name).strip())
    yield f"{base}{ext}"
    yield f"{base.strip().lower()}{ext.lower()}"
    for e in (".png", ".jpg", ".jpeg", ".PNG", ".JPG", ".JPEG"):
        yield f"{base}{e}"
        yield f"{base.strip().lower()}{e}"

MISSING_IMAGES = set()

def file_to_data_url(path: str) -> str:
    ext = os.path.splitext(path)[1].lower()
    mime = "image/png" if ext == ".png" else "image/jpeg"
    with open(path, "rb") as f:
        data = base64.b64encode(f.read()).decode("ascii")
    return f"data:{mime};base64,{data}"


def resolve_image(row):
    img_col = str(row.get("image", "") or "").strip()
    ldap_val = str(row.get("ldap", "") or "").strip()

    # ì ˆëŒ€ URL/data URIë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if img_col.startswith(("http://", "https://", "data:")):
        return img_col

    candidates = []
    # CSV íŒŒì¼ëª… ê¸°ë°˜ í›„ë³´
    for v in _variants(img_col):
        if v:
            candidates.append(os.path.join(IMG_DIR, v))

    # ldap ê¸°ë°˜ ìë™ í›„ë³´
    if ldap_val:
        for ext in (".png", ".jpg", ".jpeg", ".PNG", ".JPG", ".JPEG"):
            candidates.append(os.path.join(IMG_DIR, ldap_val + ext))
            candidates.append(os.path.join(IMG_DIR, ldap_val.lower() + ext))

    for path in candidates:
        if os.path.exists(path):
            return file_to_data_url(path)

    display_name = str(row.get("ì´ë¦„", "")) or ldap_val or "(unknown)"
    want = img_col or f"{ldap_val}.png/.jpg"
    MISSING_IMAGES.add(f"{display_name} -> {want}")
    # ì•ˆì „ í´ë°± ì´ë¯¸ì§€
    return "https://via.placeholder.com/120?text=No+Image"

# ---------------- ìœ í‹¸: ì—°ë„ ì •ê·œí™” ----------------
YEAR_RE = re.compile(r"(19|20)\d{2}")

def extract_year(v):
    if v is None:
        return None
    s = str(v)
    m = YEAR_RE.search(s)
    if m:
        try:
            return int(m.group())
        except Exception:
            return None
    # '94' ê°™ì€ 2ìë¦¬ ì²˜ë¦¬
    m2 = re.search(r"(?<!\d)(\d{2})(?!\d)", s)
    if m2:
        yy = int(m2.group(1))
        return 1900 + yy if yy >= 50 else 2000 + yy
    return None

# ì •ê·œí™”ëœ ì—°ë„ ì»¬ëŸ¼ ì¶”ê°€ (í•„í„° ë“±ì— í™œìš©)
df["íƒ„ìƒë…„ë„_Y"] = df.get("íƒ„ìƒë…„ë„").apply(extract_year) if "íƒ„ìƒë…„ë„" in df.columns else None
df["ì…ì‚¬ë…„ë„_Y"] = df.get("ì…ì‚¬ë…„ë„").apply(extract_year) if "ì…ì‚¬ë…„ë„" in df.columns else None

# ---------------- MBTI í•„í„° ì ìš© ----------------

def mbti_list(series):
    vals = sorted([m for m in series.dropna().astype(str).unique() if m and m.lower() != "nan"])
    return ["(ì „ì²´)"] + vals

mbti_exact = mbti_exact_placeholder.selectbox(
    "ì •í™•íˆ(ì„ íƒ)",
    options=mbti_list(df.get("MBTI", pd.Series([]))),
    index=0,
    key="mbti_exact",
)


def keep_by_ei(m):
    if ei_filter == "(ì „ì²´)" or not m:
        return True
    first = str(m)[:1]
    return (ei_filter == "Eë§Œ" and first == "E") or (ei_filter == "Ië§Œ" and first == "I")


def keep_by_tf(m):
    if tf_filter == "(ì „ì²´)" or not m:
        return True
    third = str(m)[2:3] if len(str(m)) >= 3 else ""
    return (tf_filter == "Të§Œ" and third == "T") or (tf_filter == "Fë§Œ" and third == "F")


def keep_by_exact(m):
    return mbti_exact == "(ì „ì²´)" or (str(m) == mbti_exact)


mask = df.apply(
    lambda r: keep_by_exact(r.get("MBTI"))
    and keep_by_ei(r.get("MBTI"))
    and keep_by_tf(r.get("MBTI")),
    axis=1,
)

# ê°€ê³µëœ ë·°
df_vis = df[mask].copy()
if df_vis.empty:
    st.warning("âš ï¸ í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ì£¼ì„¸ìš”.")
    df_vis = df.copy()

# ---------------- node_id ìƒì„± ----------------

def node_id_from_row(r):
    val = str(r.get("ldap", "") or "").strip()
    return val if val else str(r["ì´ë¦„"])  # ldap ì—†ìœ¼ë©´ ì´ë¦„ ì‚¬ìš©


df["node_id"] = df.apply(node_id_from_row, axis=1)
df_vis["node_id"] = df_vis.apply(node_id_from_row, axis=1)

# ---------------- Sidebar: ê²€ìƒ‰ ë°•ìŠ¤ ----------------
focus_node = ""
with search_box_placeholder.container():
    st.subheader("ğŸ” ë…¸ë“œ ê²€ìƒ‰")
    query = st.text_input("ì´ë¦„ ë˜ëŠ” ldap", key="search_query")
    if query:
        cond = (
            df_vis["ì´ë¦„"].astype(str).str.contains(query, case=False, na=False)
            | df_vis["ldap"].astype(str).str.contains(query, case=False, na=False)
        )
        matches = df_vis[cond]
        if not matches.empty:
            options = [f"{row['ì´ë¦„']} ({row['ldap']})" for _, row in matches.iterrows()]
            choice = st.selectbox("ê²€ìƒ‰ ê²°ê³¼", options, key="search_result")
            if "(" in choice and choice.endswith(")"):
                chosen_ldap = choice.split("(")[-1][:-1]
                row = df[df["ldap"] == chosen_ldap].iloc[0]
                focus_node = row["node_id"]
        else:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ---------------- ê·¸ë˜í”„ ìƒì„± ê³µí†µ ìœ í‹¸ ----------------
rank_size = {"ì‹¤ì¥": 20, "ì…€ì¥": 16, "ì…€ì›": 12}


def is_filled(v):
    if v is None:
        return False
    s = str(v).strip()
    if s == "":
        return False
    if s.lower() in ("nan", "none", "null"):
        return False
    return True


def valid_equal(a, b):
    if not is_filled(a) or not is_filled(b):
        return False
    return str(a).strip() == str(b).strip()

# MBTI ìƒ‰ìƒ (í…Œë‘ë¦¬)
MBTI_COLORS = {
    "INFJ": "#6366f1",
    "INFP": "#22c55e",
    "INTJ": "#0ea5e9",
    "INTP": "#6366f1",
    "ISFP": "#22c55e",
    "ENFP": "#f97316",
    "ENFJ": "#ec4899",
    "ESFJ": "#eab308",
    "ESFP": "#a855f7",
}


def mbti_color(m):
    m = str(m or "").strip()
    return MBTI_COLORS.get(m, "#9ca3af")

def is_kakao_division(v):
    """'ì¹´ì¹´ì˜¤' ë¬¸ìì—´ì´ ë“¤ì–´ê°€ë©´ ì¹´ì¹´ì˜¤ ë¶„ì‚¬ë¡œ ê°„ì£¼"""
    if v is None:
        return False
    return "ì¹´ì¹´ì˜¤" in str(v)

# ---------------- ë¹„ìŠ·í•œ ì‚¬ëŒ TOP3 ê³„ì‚° (ì—£ì§€ ì¡°ê±´ê³¼ ë™ì¼í•˜ê²Œ) ----------------
similar_map = {}
rows_full = df.to_dict("records")

# ì´ˆê¸°í™”
for r in rows_full:
    similar_map[r.get("node_id")] = []

for i in range(len(rows_full)):
    for j in range(i + 1, len(rows_full)):
        r1, r2 = rows_full[i], rows_full[j]
        nid1, nid2 = r1["node_id"], r2["node_id"]

        reasons = []

        # ì†Œì†
        if (show_edge_all or show_edge_dept) and valid_equal(r1.get("ì†Œì†"), r2.get("ì†Œì†")):
            reasons.append("ì†Œì†")

        # ì§ìœ„
        if (show_edge_all or show_edge_role) and valid_equal(r1.get("ì§ìœ„"), r2.get("ì§ìœ„")):
            reasons.append("ì§ìœ„")

        # íƒ„ìƒë…„ë„
        if (show_edge_all or show_edge_birth) and valid_equal(
            extract_year(r1.get("íƒ„ìƒë…„ë„")),
            extract_year(r2.get("íƒ„ìƒë…„ë„")),
        ):
            reasons.append("íƒ„ìƒë…„ë„")

        # ë™ê¸°
        if (show_edge_all or show_edge_cohort) and valid_equal(r1.get("ë™ê¸° ì—¬ë¶€"), r2.get("ë™ê¸° ì—¬ë¶€")):
            reasons.append("ë™ê¸°")

        # ì¹´ì¹´ì˜¤ ë¶„ì‚¬
        if (show_edge_all or show_edge_kakao):
            k1 = is_kakao_division(r1.get("ì¹´ì¹´ì˜¤ë¶„ì‚¬"))
            k2 = is_kakao_division(r2.get("ì¹´ì¹´ì˜¤ë¶„ì‚¬"))
            if k1 and k2:
                reasons.append("ì¹´ì¹´ì˜¤ ë¶„ì‚¬")

        # ì„±ë³„
        if (show_edge_all or show_edge_sex) and valid_equal(r1.get("ì„±ë³„"), r2.get("ì„±ë³„")):
            reasons.append("ì„±ë³„")

        # ì…ì‚¬ë…„ë„
        if (show_edge_all or show_edge_joinyear) and valid_equal(
            extract_year(r1.get("ì…ì‚¬ë…„ë„")),
            extract_year(r2.get("ì…ì‚¬ë…„ë„")),
        ):
            reasons.append("ì…ì‚¬ë…„ë„")

        # MBTI
        if (show_edge_all or show_edge_mbti) and valid_equal(r1.get("MBTI"), r2.get("MBTI")):
            reasons.append("MBTI")

        # í˜ˆì•¡í˜•
        if (show_edge_all or show_edge_blood) and valid_equal(r1.get("í˜ˆì•¡í˜•"), r2.get("í˜ˆì•¡í˜•")):
            reasons.append("í˜ˆì•¡í˜•")

        score = len(reasons)
        if score == 0:
            continue

        reason_text = ", ".join(reasons)
        entry1 = {
            "name": r2.get("ì´ë¦„", ""),
            "ldap": r2.get("ldap", ""),
            "score": score,
            "reasons": reason_text,
        }
        entry2 = {
            "name": r1.get("ì´ë¦„", ""),
            "ldap": r1.get("ldap", ""),
            "score": score,
            "reasons": reason_text,
        }

        similar_map[nid1].append(entry1)
        similar_map[nid2].append(entry2)

# ê° ë…¸ë“œë³„ TOP3ë§Œ ë‚¨ê¸°ê¸°
for nid, lst in similar_map.items():
    lst.sort(key=lambda x: x["score"], reverse=True)
    similar_map[nid] = lst[:3]

# ---------------- ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜ ----------------

def make_graph(df_people: pd.DataFrame):
    G = nx.Graph()
    for _, r in df_people.iterrows():
        nid = r["node_id"]
        name = str(r["ì´ë¦„"]) if "ì´ë¦„" in r else nid
        dept = str(r.get("ì†Œì†", ""))
        img = resolve_image(r)
        title = "<br>".join(
            [
                f"ì´ë¦„: {name}",
                f"ldap: {str(r.get('ldap',''))}",
                f"ì†Œì†: {dept}",
                f"ì§ìœ„: {str(r.get('ì§ìœ„',''))}",
                f"ì§êµ°: {str(r.get('ì§êµ°',''))}",
                f"íƒ„ìƒë…„ë„: {str(extract_year(r.get('íƒ„ìƒë…„ë„')) or '')}",
                f"ì…ì‚¬ë…„ë„: {str(extract_year(r.get('ì…ì‚¬ë…„ë„')) or '')}",
                f"MBTI: {str(r.get('MBTI',''))}",
                f"í˜ˆì•¡í˜•: {str(r.get('í˜ˆì•¡í˜•',''))}",
                f"ë™ê¸° ì—¬ë¶€: {str(r.get('ë™ê¸° ì—¬ë¶€',''))}",
            ]
        )
        border_color = mbti_color(r.get("MBTI"))
        color_dict = {
            "border": border_color,
            "background": "#ffffff",
            "highlight": {"border": border_color, "background": "#ffffff"},
            "hover": {"border": border_color, "background": "#f9fafb"},
        }
        node_kwargs = dict(title=title, group=dept, color=color_dict)
        if show_labels:
            node_kwargs["label"] = name
        if img:
            node_kwargs.update(shape="circularImage", image=img)
        G.add_node(nid, **node_kwargs)

    rows = df_people.to_dict("records")
    for i in range(len(rows)):
        for j in range(i + 1, len(rows)):
            r1, r2 = rows[i], rows[j]
            reasons = []  # (edge_type, label)

            # ì†Œì†
            if (show_edge_all or show_edge_dept) and valid_equal(r1.get("ì†Œì†"), r2.get("ì†Œì†")):
                reasons.append(("ì†Œì†", "ê°™ì€ ì†Œì†"))

            # ì§ìœ„
            if (show_edge_all or show_edge_role) and valid_equal(r1.get("ì§ìœ„"), r2.get("ì§ìœ„")):
                reasons.append(("ì§ìœ„", "ê°™ì€ ì§ìœ„"))

            # íƒ„ìƒë…„ë„
            if (show_edge_all or show_edge_birth) and valid_equal(
                extract_year(r1.get("íƒ„ìƒë…„ë„")),
                extract_year(r2.get("íƒ„ìƒë…„ë„")),
            ):
                reasons.append(("íƒ„ìƒë…„ë„", "ê°™ì€ íƒ„ìƒë…„ë„"))

            # ë™ê¸°
            if (show_edge_all or show_edge_cohort) and valid_equal(r1.get("ë™ê¸° ì—¬ë¶€"), r2.get("ë™ê¸° ì—¬ë¶€")):
                reasons.append(("ë™ê¸°", "ê°™ì€ ë™ê¸°"))

            # ì¹´ì¹´ì˜¤ ë¶„ì‚¬ ì—¬ë¶€
            if (show_edge_all or show_edge_kakao):
                k1 = is_kakao_division(r1.get("ì¹´ì¹´ì˜¤ë¶„ì‚¬"))
                k2 = is_kakao_division(r2.get("ì¹´ì¹´ì˜¤ë¶„ì‚¬"))
                if k1 and k2:
                    reasons.append(("ì¹´ì¹´ì˜¤", "ì¹´ì¹´ì˜¤ ë¶„ì‚¬"))

            # ì„±ë³„
            if (show_edge_all or show_edge_sex) and valid_equal(r1.get("ì„±ë³„"), r2.get("ì„±ë³„")):
                reasons.append(("ì„±ë³„", "ê°™ì€ ì„±ë³„"))

            # ì…ì‚¬ë…„ë„
            if (show_edge_all or show_edge_joinyear) and valid_equal(
                extract_year(r1.get("ì…ì‚¬ë…„ë„")),
                extract_year(r2.get("ì…ì‚¬ë…„ë„")),
            ):
                reasons.append(("ì…ì‚¬ë…„ë„", "ê°™ì€ ì…ì‚¬ë…„ë„"))

            # MBTI
            if (show_edge_all or show_edge_mbti) and valid_equal(r1.get("MBTI"), r2.get("MBTI")):
                reasons.append(("MBTI", "ê°™ì€ MBTI"))

            # í˜ˆì•¡í˜•
            if (show_edge_all or show_edge_blood) and valid_equal(r1.get("í˜ˆì•¡í˜•"), r2.get("í˜ˆì•¡í˜•")):
                reasons.append(("í˜ˆì•¡í˜•", "ê°™ì€ í˜ˆì•¡í˜•"))

            if len(reasons) == 0:
                continue

            weight = len(reasons)
            edge_type = reasons[0][0]  # ìš°ì„ ìˆœìœ„ëŠ” ì¶”ê°€ ìˆœì„œëŒ€ë¡œ
            labels = [lab for _, lab in reasons]
            title = " / ".join(labels) + f" (ì¡°ê±´ {weight}ê°œ ì¼ì¹˜)"

            G.add_edge(r1["node_id"], r2["node_id"], weight=weight, title=title, edge_type=edge_type)
    return G


G = make_graph(df_vis)

# ---------------- ë„¤íŠ¸ì›Œí¬ í†µê³„ ----------------
deg = dict(G.degree())
# ì†Œì†/MBTI/ë™ê¸° ë§µ
dept_map = df.set_index("node_id")["ì†Œì†"].to_dict()
mbti_map = df.set_index("node_id")["MBTI"].to_dict()
cohort_map = df.set_index("node_id")["ë™ê¸° ì—¬ë¶€"].to_dict()

stats = {}
for nid in G.nodes():
    dept = dept_map.get(nid, ""); mbti = mbti_map.get(nid, ""); cohort = cohort_map.get(nid, "")
    same_dept = sum(1 for v in dept_map.values() if v == dept) - 1 if dept else 0
    same_mbti = sum(1 for v in mbti_map.values() if v == mbti) - 1 if mbti else 0
    same_cohort = sum(1 for v in cohort_map.values() if v == cohort) - 1 if cohort else 0
    stats[nid] = {"degree": deg.get(nid, 0), "same_dept": max(same_dept, 0), "same_mbti": max(same_mbti, 0), "same_cohort": max(same_cohort, 0)}


def sized(nid):
    row = df.loc[df["node_id"] == nid]
    rank = row["ì§ìœ„"].iloc[0] if not row.empty else ""
    base_rank = {"ì‹¤ì¥": 20, "ì…€ì¥": 16, "ì…€ì›": 12}.get(str(rank), 12)
    return base_node_size + base_rank + degree_scale * deg.get(nid, 0)

# ---------------- PyVis ë„¤íŠ¸ì›Œí¬ ----------------
net = Network(height="800px", width="100%", bgcolor="#ffffff", font_color="black")
if physics == "barnes_hut":
    net.barnes_hut()
elif physics == "force_atlas_2based":
    net.force_atlas_2based()
else:
    net.repulsion()

# ë ˆì´ì•„ì›ƒ: ì†Œì† + ë™ê¸° ê·¸ë£¹ë³„ í´ëŸ¬ìŠ¤í„°
depths = sorted(df_vis["ì†Œì†"].dropna().unique())
depth_x = {d: i * 400 for i, d in enumerate(depths)}
cohorts = df_vis["ë™ê¸° ì—¬ë¶€"].dropna().astype(str).str.strip()
cohort_vals = sorted([c for c in cohorts.unique() if c])
cohort_y = {c: idx * 250 for idx, c in enumerate(cohort_vals)}
cohort_y["(none)"] = len(cohort_vals) * 250

for n, data in G.nodes(data=True):
    row = df[df["node_id"] == n].iloc[0]
    dept = str(row.get("ì†Œì†", ""))
    cval = str(row.get("ë™ê¸° ì—¬ë¶€", "") or "").strip()
    x = depth_x.get(dept, 0)
    y = cohort_y.get(cval if cval else "(none)", 0)
    net.add_node(n, size=sized(n), x=x, y=y, physics=True, **data)

EDGE_COLORS = {
    "ì†Œì†": "#22c55e",
    "ì§ìœ„": "#16a34a",
    "íƒ„ìƒë…„ë„": "#0ea5e9",
    "ë™ê¸°": "#3b82f6",
    "ì¹´ì¹´ì˜¤": "#f59e0b",
    "ì„±ë³„": "#ec4899",
    "ì…ì‚¬ë…„ë„": "#a855f7",
    "MBTI": "#ef4444",
    "í˜ˆì•¡í˜•": "#f97316",
    "ê¸°íƒ€": "#9ca3af",
}

for u, v, data_e in G.edges(data=True):
    edge_type = data_e.get("edge_type", "ê¸°íƒ€")
    color = EDGE_COLORS.get(edge_type, "#9ca3af")
    w = data_e.get("weight", 1)
    thickness = 1 + (w * 1.3)
    length = max(80, 280 - 40 * w)

    net.add_edge(
        u, v,
        value=thickness,
        title=data_e.get("title", ""),
        color=color,
        length=length
    )

# ---------------- í´ë¦­ íŒ¨ë„ & ê²€ìƒ‰ í¬ì»¤ìŠ¤ JS ----------------
meta = {}
for _, r in df.iterrows():
    nid = r["node_id"]
    meta[nid] = {
        "ì´ë¦„": str(r.get("ì´ë¦„", "")),
        "ldap": str(r.get("ldap", "")),
        "ì†Œì†": str(r.get("ì†Œì†", "")),
        "ì§ìœ„": str(r.get("ì§ìœ„", "")),
        "ì§êµ°": str(r.get("ì§êµ°", "")),
        "ì…ì‚¬ë…„ë„": str(extract_year(r.get("ì…ì‚¬ë…„ë„")) or ""),
        "MBTI": str(r.get("MBTI", "")),
        "í˜ˆì•¡í˜•": str(r.get("í˜ˆì•¡í˜•", "")),
        "ë™ê¸° ì—¬ë¶€": str(r.get("ë™ê¸° ì—¬ë¶€", "")),
        "ì—°ê²° ìˆ˜": stats.get(nid, {}).get("degree", 0),
        "ê°™ì€ ì†Œì† ìˆ˜": stats.get(nid, {}).get("same_dept", 0),
        "ê°™ì€ MBTI ìˆ˜": stats.get(nid, {}).get("same_mbti", 0),
        "ê°™ì€ ë™ê¸° ìˆ˜": stats.get(nid, {}).get("same_cohort", 0),
        "similar": similar_map.get(nid, []),
    }

html_file = "network.html"
net.save_graph(html_file)
with open(html_file, "r", encoding="utf-8") as f:
    html_src = f.read()

focus_node_json = json.dumps(focus_node, ensure_ascii=False)

panel_js = f"""
<script>
window.nodeMeta = {json.dumps(meta, ensure_ascii=False)};
(function() {{
  const panelId = 'profilePanel';
  let panel = document.getElementById(panelId);
  if (!panel) {{
    panel = document.createElement('div');
    panel.id = panelId;
    panel.style.position='fixed'; panel.style.top='20px'; panel.style.right='20px';
    panel.style.width='260px'; panel.style.maxHeight='65vh'; panel.style.overflow='auto';
    panel.style.border='1px solid #e5e7eb'; panel.style.borderRadius='12px';
    panel.style.padding='10px'; panel.style.background='rgba(255,255,255,0.9)';
    panel.style.boxShadow='0 4px 12px rgba(0,0,0,0.1)'; panel.style.fontSize='13px';
    panel.style.lineHeight='1.35';
    panel.innerHTML = '<b>ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</b><br><small>ë¹ˆ ê³µê°„ì„ í´ë¦­í•˜ë©´ ì „ì²´ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ì‹œ ë³´ì…ë‹ˆë‹¤.</small>';
    document.body.appendChild(panel);
  }}
  if (typeof network !== 'undefined') {{
    var nodes = network.body.data.nodes; var edges = network.body.data.edges;
    var allNodes = nodes.get({{returnType:'Object'}}); var allEdges = edges.get({{returnType:'Object'}});
    function focusOnNode(nid) {{
      var connectedNodes = network.getConnectedNodes(nid); connectedNodes.push(nid);
      var updatesNodes = []; for (var id in allNodes) {{
        var visible = connectedNodes.indexOf(id) !== -1 || connectedNodes.indexOf(parseInt(id)) !== -1;
        updatesNodes.push({{id: id, hidden: !visible}});
      }} nodes.update(updatesNodes);
      var connectedEdges = network.getConnectedEdges(nid); var updatesEdges = []; for (var eid in allEdges) {{
        var visibleE = connectedEdges.indexOf(eid) !== -1 || connectedEdges.indexOf(parseInt(eid)) !== -1;
        updatesEdges.push({{id: eid, hidden: !visibleE}});
      }} edges.update(updatesEdges);
      try {{ network.focus(nid, {{scale: 1.5, animation: true}}); }} catch(e) {{}}
    }}
    function resetView() {{
      var updatesNodes = []; for (var id in allNodes) {{ updatesNodes.push({{id: id, hidden: false}}); }} nodes.update(updatesNodes);
      var updatesEdges = []; for (var eid in allEdges) {{ updatesEdges.push({{id: eid, hidden: false}}); }} edges.update(updatesEdges);
      network.fit({{}});
    }}
    var initialFocusNode = {focus_node_json}; if (initialFocusNode) {{ setTimeout(function() {{ try {{ network.selectNodes([initialFocusNode]); focusOnNode(initialFocusNode); }} catch(e) {{}} }}, 600); }}
    network.on('click', function(params) {{
      if (params.nodes && params.nodes.length > 0) {{
        var nid = params.nodes[0]; var m = (window.nodeMeta || {{}})[nid] || {{}};
        var sims = m['similar'] || []; var simsHtml = '';
        if (sims.length > 0) {{
          simsHtml += '<hr><div><b>ê°€ì¥ ë¹„ìŠ·í•œ ì‚¬ëŒ TOP3</b><ol style="padding-left:18px; margin:4px 0;">';
          for (var i = 0; i < sims.length; i++) {{
            var s = sims[i]; var label = (s.name || '') + (s.ldap ? ' (' + s.ldap + ')' : '');
            var reasonTxt = s.reasons ? ' - ' + s.reasons + ' ì¼ì¹˜' : '';
            simsHtml += '<li>' + label + ' (ì¡°ê±´ ' + (s.score || 0) + 'ê°œ ì¼ì¹˜' + reasonTxt + ')</li>';
          }} simsHtml += '</ol></div>';
        }}
        panel.innerHTML =
          '<h3 style="margin:0 0 6px 0;">' + (m['ì´ë¦„']||nid) + '</h3>' +
          '<div><b>ldap</b>: ' + (m['ldap']||'') + '</div>' +
          '<div><b>ì†Œì†</b>: ' + (m['ì†Œì†']||'') + '</div>' +
          '<div><b>ì§ìœ„</b>: ' + (m['ì§ìœ„']||'') + '</div>' +
          '<div><b>ì§êµ°</b>: ' + (m['ì§êµ°']||'') + '</div>' +
          '<div><b>ì…ì‚¬ë…„ë„</b>: ' + (m['ì…ì‚¬ë…„ë„']||'') + '</div>' +
          '<div><b>MBTI</b>: ' + (m['MBTI']||'') + '</div>' +
          '<div><b>í˜ˆì•¡í˜•</b>: ' + (m['í˜ˆì•¡í˜•']||'') + '</div>' +
          '<div><b>ë™ê¸° ì—¬ë¶€</b>: ' + (m['ë™ê¸° ì—¬ë¶€']||'') + '</div>' +
          '<hr>' +
          '<div><b>ì—°ê²° ìˆ˜</b>: ' + (m['ì—°ê²° ìˆ˜']||0) + '</div>' +
          '<div><b>ê°™ì€ ì†Œì† ì¸ì›</b>: ' + (m['ê°™ì€ ì†Œì† ìˆ˜']||0) + '</div>' +
          '<div><b>ê°™ì€ MBTI ì¸ì›</b>: ' + (m['ê°™ì€ MBTI ìˆ˜']||0) + '</div>' +
          '<div><b>ê°™ì€ ë™ê¸° ì¸ì›</b>: ' + (m['ê°™ì€ ë™ê¸° ìˆ˜']||0) + '</div>' +
          simsHtml +
          '<hr><small>ì´ ë…¸ë“œì™€ ì—°ê²°ëœ ê´€ê³„ë§Œ í‘œì‹œë©ë‹ˆë‹¤. ë¹ˆ ê³µê°„ì„ í´ë¦­í•˜ë©´ ì „ì²´ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ì‹œ ë³´ì…ë‹ˆë‹¤.</small>';
        focusOnNode(nid);
      }} else {{ panel.innerHTML = '<b>ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</b><br><small>ë¹ˆ ê³µê°„ì„ í´ë¦­í•˜ë©´ ì „ì²´ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ì‹œ ë³´ì…ë‹ˆë‹¤.</small>'; resetView(); }}
    }});
  }}
}})();
</script>
"""

html_src = html_src.replace("</body>", panel_js + "\n</body>")

# ğŸ” ì—£ì§€ ìƒ‰ìƒ ì„¤ëª… (ë„¤íŠ¸ì›Œí¬ ìœ„ìª½)
legend_html = """
<div style="margin-top:8px; font-size:13px;">
  <b>ì—£ì§€ ìƒ‰ìƒ ì˜ë¯¸</b><br>
  <div style="display:flex; flex-wrap:wrap; gap:6px; margin-top:4px;">
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#22c55e;"></span> ì†Œì†
    </span>
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#16a34a;"></span> ì§ìœ„
    </span>
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#0ea5e9;"></span> íƒ„ìƒë…„ë„
    </span>
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#3b82f6;"></span> ë™ê¸°
    </span>
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#f59e0b;"></span> ì¹´ì¹´ì˜¤ ë¶„ì‚¬
    </span>
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#ec4899;"></span> ì„±ë³„
    </span>
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#a855f7;"></span> ì…ì‚¬ë…„ë„
    </span>
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#ef4444;"></span> MBTI
    </span>
    <span style="display:inline-flex; align-items:center; gap:4px;">
      <span style="display:inline-block; width:14px; height:4px; background:#f97316;"></span> í˜ˆì•¡í˜•
    </span>
  </div>
  <div style="margin-top:2px; color:#6b7280;">(ì„ ì´ ë‘êº¼ìš¸ìˆ˜ë¡ ì¡°ê±´ì´ ë” ë§ì´ ê²¹ì¹œë‹¤ëŠ” ëœ»)</div>
</div>
"""
st.markdown(legend_html, unsafe_allow_html=True)

html(html_src, height=820, scrolling=True)

# â—ë¯¸í•´ê²° ì´ë¯¸ì§€ ëª©ë¡ í‘œì‹œ
if MISSING_IMAGES:
    st.sidebar.markdown("### â—ë¯¸í•´ê²° ì´ë¯¸ì§€")
    for msg in sorted(MISSING_IMAGES):
        st.sidebar.write(msg)


def generate_team_intro(df: pd.DataFrame) -> str:
    """
    dfë¥¼ ìš”ì•½í•´ì„œ íŒ€ ì†Œê°œê¸€ ì´ˆì•ˆì„ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜ (OpenAI ì‚¬ìš©)
    """
    wanted_cols = [
        "ì´ë¦„", "ì†Œì†", "ì§ìœ„", "ì§êµ°",
        "ì…ì‚¬ë…„ë„", "MBTI", "í˜ˆì•¡í˜•",
        "ì›Œí¬ìƒµì„±í–¥(2025)", "ê±°ì£¼ì§€",
    ]
    cols = [c for c in wanted_cols if c in df.columns]
    people = df[cols].to_dict(orient="records")

    if len(people) > 100:
        people = people[:100]

    messages = [
        {
            "role": "system",
            "content": (
                "ë„ˆëŠ” í•œêµ­ IT íšŒì‚¬ì˜ ë°ì´í„°ë¶„ì„íŒ€ ì†Œê°œê¸€ì„ ì¨ì£¼ëŠ” ì‘ê°€ì•¼. "
                "ì‚¬ë‚´ ìœ„í‚¤/ë…¸ì…˜ì— ì˜¬ë¦´ ë¬¸ì„œë¼ê³  ìƒê°í•˜ê³ , ë„ˆë¬´ ë”±ë”±í•˜ì§€ ì•Šì€ ì¡´ëŒ“ë§ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì¤˜."
            ),
        },
        {
            "role": "user",
            "content": f"""
ë‹¤ìŒì€ ìš°ë¦¬ íŒ€ì›ë“¤ì˜ ì •ë³´ì•¼. (ê° í•­ëª©ì€ JSON í•œ ì¤„ë¡œ ë˜ì–´ ìˆìŒ)

- íŒ€ ì „ì²´ì ì¸ íŠ¹ì§• (ê·œëª¨, ì†Œì† êµ¬ì„±, ì—­í• /ì§êµ°, MBTI ë¶„í¬ ëŠë‚Œ ë“±)
- ì¼í•  ë•Œ ë¶„ìœ„ê¸°/ì»¬ëŸ¬
- ì›Œí¬ìƒµ/íšŒì‹ ìŠ¤íƒ€ì¼ í•œë‘ ê°€ì§€ ì œì•ˆ
- ìƒˆë¡œ í•©ë¥˜í•œ ì‚¬ëŒì—ê²Œ í•´ì£¼ë©´ ì¢‹ì„ í•œ ì¤„ ì¡°ì–¸

ìœ„ 4ê°€ì§€ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, 4~7ë‹¨ë½ ì •ë„ì˜ í•œêµ­ì–´ ì†Œê°œê¸€ì„ ì‘ì„±í•´ì¤˜.
ì´ë¦„ì€ ì¼ì¼ì´ ë‹¤ ë‚˜ì—´í•˜ì§€ ë§ê³ , ì „ì²´ì ì¸ ê²½í–¥ ìœ„ì£¼ë¡œ ì¨ì¤˜.

[íŒ€ ë°ì´í„°]
{people}
""",
        },
    ]

    resp = client.chat.completions.create(
        model="gpt-4o-mini",   # ë˜ëŠ” gpt-4.1-mini
        messages=messages,
        temperature=0.8,
    )
    return resp.choices[0].message.content.strip()





# --------- ë§‰ëŒ€ ê·¸ë˜í”„ í—¬í¼ ---------
def plot_bar_with_labels(data, title, xlabel="", ylabel=""):
    fig, ax = plt.subplots()
    bars = ax.bar(data.index.astype(str), data.values)

    for bar in bars:
        yval = bar.get_height()
        ax.text(
            bar.get_x() + bar.get_width()/2,
            yval,
            f"{yval:.0f}",
            ha="center",
            va="bottom",
            fontsize=9,
        )

    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    plt.xticks(rotation=45)
    plt.tight_layout()
    return fig

# ---------------- ğŸ“Š MBTI / ì…ì‚¬ë…„ë„ + I/E, T/F ----------------
with st.expander("ğŸ“Š MBTI / ì…ì‚¬ë…„ë„ ë¶„í¬ + I/E Â· T/F ë¹„ìœ¨"):
    col1, col2 = st.columns(2)

    # ì „ì²´ MBTI ë¶„í¬
    mbti_series = df["MBTI"].dropna().astype(str).str.strip()
    mbti_series = mbti_series[mbti_series != ""]
    if not mbti_series.empty:
        mbti_counts = mbti_series.value_counts().sort_index()
        col1.markdown("**MBTI ë¶„í¬**")
        fig = plot_bar_with_labels(mbti_counts, "MBTI ë¶„í¬", ylabel="Count")
        col1.pyplot(fig)
    else:
        col1.info("MBTI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ì…ì‚¬ë…„ë„ ë¶„í¬
    if "ì…ì‚¬ë…„ë„" in df.columns:
        years = df["ì…ì‚¬ë…„ë„"].apply(extract_year).dropna().astype(int)
        if not years.empty:
            year_counts = years.value_counts().sort_index()
            col2.markdown("**ì…ì‚¬ë…„ë„ ë¶„í¬ (ì •ê·œí™”)**")
            fig2 = plot_bar_with_labels(year_counts, "ì…ì‚¬ë…„ë„ ë¶„í¬", ylabel="Count")
            col2.pyplot(fig2)
        else:
            col2.info("ì…ì‚¬ë…„ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        col2.info("ì…ì‚¬ë…„ë„ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.markdown("### ğŸŒ ì „ì²´ MBTI I/E, T/F ë¹„ìœ¨ (íŒŒì´ì°¨íŠ¸)")

    # ì „ì²´ I/E, T/F ë¹„ìœ¨
    if "MBTI" in df.columns:
        overall_mbti = df["MBTI"].dropna().astype(str).str.strip()
        overall_mbti = overall_mbti[overall_mbti != ""]
        overall_mbti = overall_mbti[overall_mbti.str.len() >= 3]
        overall_mbti = overall_mbti[~overall_mbti.str.contains(r"\?", regex=True)]

        if not overall_mbti.empty:
            overall_IE = overall_mbti.str[0]   # I / E
            overall_TF = overall_mbti.str[2]   # T / F

            p1, p2 = st.columns(2)

            # ì „ì²´ I/E íŒŒì´ì°¨íŠ¸
            ie_counts_overall = overall_IE.value_counts()
            count_I = int(ie_counts_overall.get("I", 0))
            count_E = int(ie_counts_overall.get("E", 0))

            if count_I + count_E > 0:
                fig_ie, ax_ie = plt.subplots()
                ax_ie.pie(
                    [count_I, count_E],
                    labels=[f"I ({count_I})", f"E ({count_E})"],
                    autopct="%1.1f%%",
                    startangle=90,
                )
                ax_ie.axis("equal")
                p1.markdown("**ì „ì²´ I / E ë¹„ìœ¨**")
                p1.pyplot(fig_ie)
            else:
                p1.info("I/E ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ì „ì²´ T/F íŒŒì´ì°¨íŠ¸
            tf_counts_overall = overall_TF.value_counts()
            count_T = int(tf_counts_overall.get("T", 0))
            count_F = int(tf_counts_overall.get("F", 0))

            if count_T + count_F > 0:
                fig_tf, ax_tf = plt.subplots()
                ax_tf.pie(
                    [count_T, count_F],
                    labels=[f"T ({count_T})", f"F ({count_F})"],
                    autopct="%1.1f%%",
                    startangle=90,
                )
                ax_tf.axis("equal")
                p2.markdown("**ì „ì²´ T / F ë¹„ìœ¨**")
                p2.pyplot(fig_tf)
            else:
                p2.info("T/F ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì „ì²´ I/E, T/F ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ MBTI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("`MBTI` ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.markdown("### ğŸ§¬ ì†Œì†ë³„ MBTI I/E, T/F ë¹„ìœ¨ (ë°ì´í„°ë¶„ì„ë© ì œì™¸)")

    if "MBTI" in df.columns and "ì†Œì†" in df.columns:
        df_mbti = df[["ì†Œì†", "MBTI"]].dropna().copy()
        df_mbti["MBTI"] = df_mbti["MBTI"].astype(str).str.strip()
        df_mbti = df_mbti[df_mbti["MBTI"].str.len() >= 3]
        df_mbti = df_mbti[~df_mbti["MBTI"].str.contains(r"\?", regex=True)]
        df_mbti = df_mbti[df_mbti["ì†Œì†"] != "ë°ì´í„°ë¶„ì„ë©"]

        if not df_mbti.empty:
            df_mbti["IE"] = df_mbti["MBTI"].str[0]
            df_mbti["TF"] = df_mbti["MBTI"].str[2]

            col3, col4 = st.columns(2)

            # ì†Œì†ë³„ I/E ë¹„ìœ¨
            ie_counts = df_mbti.groupby(["ì†Œì†", "IE"]).size().unstack(fill_value=0)
            for c in ["I", "E"]:
                if c not in ie_counts.columns:
                    ie_counts[c] = 0

            denom_ie = (ie_counts["I"] + ie_counts["E"]).replace(0, pd.NA)
            ie_ratio_I = (ie_counts["I"] / denom_ie).fillna(0)
            ie_ratio_E = (ie_counts["E"] / denom_ie).fillna(0)

            ie_ratio_df = pd.DataFrame(
                {
                    "I ë¹„ìœ¨": ie_ratio_I,
                    "E ë¹„ìœ¨": ie_ratio_E,
                }
            )
            ie_ratio_percent = ie_ratio_df * 100
            ie_ratio_flat = ie_ratio_percent.stack()
            ie_ratio_flat.index = [
                f"{dept} - {kind}" for dept, kind in ie_ratio_flat.index
            ]

            col3.markdown("**ì†Œì†ë³„ I / E ë¹„ìœ¨ (%)**")
            fig3 = plot_bar_with_labels(ie_ratio_flat, "ì†Œì†ë³„ I/E ë¹„ìœ¨ (%)", ylabel="%")
            col3.pyplot(fig3)

            # ì†Œì†ë³„ T/F ë¹„ìœ¨
            tf_counts = df_mbti.groupby(["ì†Œì†", "TF"]).size().unstack(fill_value=0)
            for c in ["T", "F"]:
                if c not in tf_counts.columns:
                    tf_counts[c] = 0

            denom_tf = (tf_counts["T"] + tf_counts["F"]).replace(0, pd.NA)
            tf_ratio_T = (tf_counts["T"] / denom_tf).fillna(0)
            tf_ratio_F = (tf_counts["F"] / denom_tf).fillna(0)

            tf_ratio_df = pd.DataFrame(
                {
                    "T ë¹„ìœ¨": tf_ratio_T,
                    "F ë¹„ìœ¨": tf_ratio_F,
                }
            )
            tf_ratio_percent = tf_ratio_df * 100
            tf_ratio_flat = tf_ratio_percent.stack()
            tf_ratio_flat.index = [
                f"{dept} - {kind}" for dept, kind in tf_ratio_flat.index
            ]

            col4.markdown("**ì†Œì†ë³„ T / F ë¹„ìœ¨ (%)**")
            fig4 = plot_bar_with_labels(tf_ratio_flat, "ì†Œì†ë³„ T/F ë¹„ìœ¨ (%)", ylabel="%")
            col4.pyplot(fig4)

        else:
            st.info("ì†Œì†ë³„ MBTI ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ MBTI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë˜ëŠ” ëª¨ë‘ ë°ì´í„°ë¶„ì„ë©ì´ë¼ ì œì™¸ë¨)")
    else:
        st.info("`ì†Œì†` ë˜ëŠ” `MBTI` ì»¬ëŸ¼ì´ ì—†ì–´ ì†Œì†ë³„ ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# ---------------- ğŸ“ AI íŒ€ ì†Œê°œê¸€ ----------------
with st.expander("ğŸ“ AIê°€ ì¨ì£¼ëŠ” íŒ€ ì†Œê°œê¸€ ì´ˆì•ˆ"):
    st.markdown(
        """
CSVì— ìˆëŠ” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ  
**ë°ì´í„°ë¶„ì„ë© / ê° ì…€ì˜ ë¶„ìœ„ê¸°, MBTI ê²½í–¥, ì›Œí¬ìƒµ/íšŒì‹ ìŠ¤íƒ€ì¼** ë“±ì„
í•œ ë²ˆì— ìš”ì•½í•œ ì†Œê°œê¸€ ì´ˆì•ˆì„ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.
"""
    )
    if st.button("íŒ€ ì†Œê°œê¸€ ìƒì„±í•˜ê¸°"):
        with st.spinner("íŒ€ ì†Œê°œê¸€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                intro_text = generate_team_intro(df)  # ğŸ”¹ í•„í„° ì „ ì›ë³¸ df ê¸°ì¤€
                st.markdown(intro_text)
            except Exception as e:
                st.error(f"ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")




# ---------------- í¬ìŠ¤í„° ë·° (ì†Œì† íŒ€ë³„ ì¸ì‡„ìš©) ----------------
with st.expander("ğŸ–¼ íŒ€ êµ¬ì„±ë„ í¬ìŠ¤í„° ë·° (ì†Œì†ë³„ ì¸ì‡„ìš© ë ˆì´ì•„ì›ƒ)"):
    st.markdown("ë¸Œë¼ìš°ì €ì—ì„œ `Print` â†’ `PDFë¡œ ì €ì¥` í•˜ë©´ ì†Œì†ë³„ í¬ìŠ¤í„°ì²˜ëŸ¼ ì“¸ ìˆ˜ ìˆì–´ìš”.")
    if "ì†Œì†" in df.columns:
        for dept, sub in df.groupby("ì†Œì†"):
            st.markdown(f"### ğŸ· {dept}")
            cols = st.columns(4)
            for idx, (_, r) in enumerate(sub.iterrows()):
                col = cols[idx % 4]
                img = resolve_image(r)
                if img:
                    col.image(img, width=120)
                jy = extract_year(r.get("ì…ì‚¬ë…„ë„"))
                col.markdown(
                    f"**{r.get('ì´ë¦„','')}**  \n"
                    f"{r.get('ì§ìœ„','')} / {r.get('ì§êµ°','')}  \n"
                    f"{(jy or '')} ì…ì‚¬ Â· {r.get('MBTI','')}"
                )
            st.markdown("---")
    else:
        st.info("ì†Œì† ì»¬ëŸ¼ì´ ì—†ì–´ í¬ìŠ¤í„° ë·°ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ---------------- ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ----------------
with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°(í•„í„° ì ìš©)"):
    st.dataframe(df_vis)
